{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module74 Clustering Ass 2"
      ],
      "metadata": {
        "id": "RtCXYnihPymM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is Hierarchical Clustering, and How is It Different from Other Clustering Techniques?"
      ],
      "metadata": {
        "id": "o5k-4o-lP0Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. Hierarchical clustering is a clustering technique that builds a hierarchy of clusters in a tree-like structure rather than forming a fixed number of clusters at the beginning.\n",
        "\n",
        "Key Differences from Other Clustering Techniques:\n",
        "\n",
        "**1.) No need to predefine K:** Unlike K-Means, hierarchical clustering does not require specifying the number of clusters in advance.\n",
        "\n",
        "**2.) Tree structure:** It produces a **dendrogram**, which allows for a flexible choice of the number of clusters.\n",
        "\n",
        "**3.) Works well with small datasets:** Hierarchical clustering can be computationally expensive for large datasets.\n",
        "\n",
        "**4.) Does not assume spherical clusters:** Unlike K-Means, it works with non-spherical and imbalanced clusters.\n"
      ],
      "metadata": {
        "id": "cPuCgPpnQCwQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfXwOtwLPu4P"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Two Main Types of Hierarchical Clustering Algorithms"
      ],
      "metadata": {
        "id": "EgIYXsyQQach"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2. The 2 types of Heirarchical Clustering Algorithms are :\n",
        "\n",
        "**1.) Agglomerative Hierarchical Clustering (Bottom-Up Approach):**\n",
        "\n",
        "Starts with each data point as its own cluster.\n",
        "\n",
        "Iteratively merges the closest clusters until all points form a single cluster.\n",
        "\n",
        "Commonly used due to its efficiency.\n",
        "\n",
        "\n",
        "**2.) Divisive Hierarchical Clustering (Top-Down Approach):**\n",
        "\n",
        "Starts with all data points in one large cluster.\n",
        "\n",
        "Iteratively splits clusters into smaller ones until each point is in its own cluster.\n",
        "\n",
        "Less common due to its higher computational cost.\n"
      ],
      "metadata": {
        "id": "geyupg3TQc--"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zYWldBqvPxrb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How to Determine Distance Between Clusters in Hierarchical Clustering?"
      ],
      "metadata": {
        "id": "Nt9k59f2Q1Se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. To Determine Distance Between Clusters in Hierarchical Clustering are :\n",
        "\n",
        "**The choice of linkage criteria defines how the distance between two clusters is calculated.**\n",
        "\n",
        "## Common Distance Metrics Used:\n",
        "\n",
        "1.) **Single Linkage:** Distance between the closest points of two clusters. (Good for elongated clusters, but sensitive to noise.)\n",
        "\n",
        "2.) **Complete Linkage:** Distance between the farthest points of two clusters. (Results in compact clusters.)\n",
        "\n",
        "3.) **Average Linkage:** Mean distance between all points in two clusters. (Balances Single and Complete Linkage.)\n",
        "\n",
        "4.) **Centroid Linkage:** Distance between the centroids of two clusters. (May not always preserve hierarchy.)\n",
        "\n",
        "5.) **Ward’s Method:** Minimizes variance within clusters. (Good for compact, spherical clusters.)\n"
      ],
      "metadata": {
        "id": "HQ5-x3dNQ2_S"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j22qrTh7RP3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How to Determine the Optimal Number of Clusters in Hierarchical Clustering?"
      ],
      "metadata": {
        "id": "-cJKYFcSRSX5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4. To determine the optimal Number of Clusters in Hierarchical Clustering, there are some common methods include:\n",
        "\n",
        "1.) **Dendrogram Cutting:**\n",
        "\n",
        "Identify the longest vertical line without intersecting horizontal merges.\n",
        "\n",
        "Cut the dendrogram at that height to determine the number of clusters.\n",
        "\n",
        "\n",
        "2.) **Elbow Method on Linkage Distance:**\n",
        "\n",
        "Plot the distance at which clusters merge (y-axis) against the number of clusters.\n",
        "\n",
        "Choose the point where the distance increases sharply.\n",
        "\n",
        "\n",
        "3.) **Silhouette Score:**\n",
        "\n",
        "Measures how well-separated clusters are.\n",
        "\n",
        "A higher score indicates better clustering.\n"
      ],
      "metadata": {
        "id": "7T_oNq-YRUIY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V24cjl7RRqOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What Are Dendrograms, and How Are They Useful?"
      ],
      "metadata": {
        "id": "Cm-hrM62Rt1S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5. A dendrogram is a tree-like diagram that represents the hierarchical structure of clusters.\n",
        "\n",
        "### How It Helps in Analysis:\n",
        "\n",
        "Shows which clusters are similar and how they merge.\n",
        "\n",
        "Helps in choosing the optimal number of clusters by cutting at a certain height.\n",
        "\n",
        "Provides flexibility, allowing different clustering levels based on the application.\n"
      ],
      "metadata": {
        "id": "_1MYVWkuRweQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lY56OF4-R1Lo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Can Hierarchical Clustering Be Used for Both Numerical and Categorical Data?"
      ],
      "metadata": {
        "id": "jgF0LhazR5Ko"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A6. Yes, Hierarchical Clustering Be Used for Both Numerical and Categorical Data but the distance metrics differ:\n",
        "\n",
        "1.) **For Numerical Data:**\n",
        "\n",
        "**Euclidean Distance** (Default, works well for continuous data).\n",
        "\n",
        "**Manhattan Distance** (Less sensitive to outliers).\n",
        "\n",
        "**Cosine Similarity** (Good for high-dimensional data).\n",
        "\n",
        "\n",
        "2.) **For Categorical Data:**\n",
        "\n",
        "**Hamming Distance** (Counts the number of differing attributes).\n",
        "\n",
        "**Jaccard Similarity** (Used for binary or categorical data).\n",
        "\n",
        "**Gower’s Distance** (Handles mixed data types).\n"
      ],
      "metadata": {
        "id": "O1y6_aA5R7qh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OgfZyUV2SV07"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. How to Identify Outliers or Anomalies Using Hierarchical Clustering?"
      ],
      "metadata": {
        "id": "5kakRI_3SZd0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A7. To Identify Outliers or Anomalies Using Hierarchical Clustering, we can use following:\n",
        "\n",
        "**Outliers tend to merge at a higher level in the dendrogram**, forming small individual clusters before merging with the main clusters.\n",
        "\n",
        "Points that are **far from all other points** in distance calculations can be flagged as anomalies.\n",
        "\n",
        "Use **single linkage** clustering to detect elongated or isolated points."
      ],
      "metadata": {
        "id": "E7DnxArfSbDV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TCRJb4mWSxN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Vj_iBPgSx9F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}