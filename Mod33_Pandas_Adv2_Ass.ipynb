{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module33 Pandas Advance2 Assignment"
      ],
      "metadata": {
        "id": "wL5kBhArKQc3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDwNND13NPv7"
      },
      "source": [
        "Consider following code to answer further questions:\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "course_name = [â€˜Data Scienceâ€™, â€˜Machine Learningâ€™, â€˜Big Dataâ€™, â€˜Data Engineerâ€™]\n",
        "duration = [2,3,6,4]\n",
        "df = pd.DataFrame(data = {â€˜course_nameâ€™ : course_name, â€˜durationâ€™ : duration})\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNZ0SqFONawl"
      },
      "source": [
        "Q1. Write a code to print the data present in the second row of the dataframe, df."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r52g9FojNXxn",
        "outputId": "a6d06342-412b-4732-c40a-c35f0b71b029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "course_name    Machine Learning\n",
            "duration                      3\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "course_name = ['Data Science', 'Machine Learning', 'Big Data', 'Data Engineer']\n",
        "duration = [2, 3, 6, 4]\n",
        "\n",
        "df = pd.DataFrame(data={'course_name': course_name, 'duration': duration})\n",
        "\n",
        "# Printing the second row (index 1)\n",
        "print(df.iloc[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jlUWTjAhNoKZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUMd_1A_Nud4"
      },
      "source": [
        "Q2. What is the difference between the functions loc and iloc in pandas.DataFrame?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzhMDujSN8RL"
      },
      "source": [
        "A2. Difference between the functions 'loc' and 'iloc' are:-\n",
        "\n",
        "loc(Label-based indexing)\n",
        "\n",
        "iloc(Integer- location based indexing)\n",
        "\n",
        "\n",
        "## Features\n",
        "\n",
        "**1. Indexing type**\n",
        "\n",
        "a.) loc- \tUses labels (row index names)\n",
        "\n",
        "b.) iloc- Uses integer positions (0-based index)\n",
        "\n",
        "**2. Selection**\n",
        "\n",
        "a.) loc- ```df.loc[2]``` selects the row where index is 2\n",
        "\n",
        "b.) iloc- ```df.iloc[2]``` selects the row at position 2 (third row)\n",
        "\n",
        "**3. Slicing**\n",
        "\n",
        "a.) loc- ```df.loc[1:3]``` includes row with index 3\n",
        "\n",
        "b.) iloc- ```df.iloc[1:3]``` excludes row at index 3\n",
        "\n",
        "**4. Column Selection**\n",
        "\n",
        "a.) loc- ```df.loc[:, 'course_name']``` selects 'course_name' column\n",
        "\n",
        "b.) iloc- ```df.iloc[:, 0]``` selects the first column\n",
        "\n",
        "**5. Error Handling**\n",
        "\n",
        "a.) loc- Throws an error if label doesnâ€™t exist\n",
        "\n",
        "b.) iloc- Works as long as index is within range\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        },
        "id": "6xVMbR_zNvLW",
        "outputId": "6882557c-34b0-4ea4-f153-b59f3e4f8ac2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>course_name</th>\n",
              "      <td>Machine Learning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>duration</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "course_name    Machine Learning\n",
              "duration                      3\n",
              "Name: 1, dtype: object"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example\n",
        "\n",
        "df.loc[1]  # Selects row where index = 1 (Machine Learning)\n",
        "df.iloc[1]  # Selects the second row (Machine Learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCKXw379PRT3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lwe1WopbPVYH"
      },
      "source": [
        "Q3. Reindex the given dataframe using a variable, ```reindex = [3,0,1,2]``` and store it in ```new_df``` then find the output for both ```new_df.loc[2]``` and ```new_df.iloc[2]```. Did you observe any difference in both the outputs? If so then explain it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDHyPSYfPh2i"
      },
      "source": [
        "A3. Reindexing Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnB9DsbbPeaG",
        "outputId": "0a1d4418-22ea-497b-9f7f-8ff5d16c28b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using loc[2]:\n",
            " course_name    Big Data\n",
            "duration              6\n",
            "Name: 2, dtype: object\n",
            "\n",
            "Using iloc[2]:\n",
            " course_name    Machine Learning\n",
            "duration                      3\n",
            "Name: 1, dtype: object\n"
          ]
        }
      ],
      "source": [
        "reindex = [3, 0, 1, 2]\n",
        "new_df = df.reindex(reindex)\n",
        "\n",
        "print(\"Using loc[2]:\\n\", new_df.loc[2])  # Uses index label\n",
        "print(\"\\nUsing iloc[2]:\\n\", new_df.iloc[2])  # Uses integer position\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EH7DnXltPutG"
      },
      "source": [
        "### Explanation:\n",
        "\n",
        "1. ```new_df.loc[2]``` selects row where index is 2 (original index of 'Big Data').\n",
        "\n",
        "2. ```new_df.iloc[2]``` selects the row at position 2 in the new order (original index 1, 'Machine Learning').\n",
        "\n",
        "3. **Observation:**\n",
        "\n",
        "a.) loc always looks for the original index label.\n",
        "\n",
        "b.) iloc ignores the index labels and works positionally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsFRPqpRPmsu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K3ZCAPVBQHLc"
      },
      "source": [
        "Q4. Write a code to find the following statistical measurements for the above dataframe df1:\n",
        "\n",
        "(i) mean of each and every column present in the dataframe.\n",
        "\n",
        "(ii) standard deviation of column, â€˜column_2â€™"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FE-LxbsQKFC"
      },
      "source": [
        "A4.\n",
        "# **Statistical Measurements in DataFrame df1**\n",
        "\n",
        "(i) Finding the Mean of Each Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sprj8UzvQ7P9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "columns = ['column_1', 'column_2', 'column_3', 'column_4', 'column_5', 'column_6']\n",
        "indices = [1, 2, 3, 4, 5, 6]\n",
        "\n",
        "# Creating a dataframe with random values\n",
        "df1 = pd.DataFrame(np.random.rand(6, 6), columns=columns, index=indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0E9X72s4QhBv"
      },
      "outputs": [],
      "source": [
        "column_means = df1.mean()\n",
        "print(\"Mean of each column:\\n\", column_means)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lkgK236QjPB"
      },
      "source": [
        "**Explanation:**\n",
        "\n",
        "1.) ```df1.mean()``` calculates the mean of each column.\n",
        "\n",
        "2.) By default, axis=0 (column-wise mean).\n",
        "\n",
        "\n",
        "(ii) Finding the Standard Deviation of ```column_2```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akpz16UxQzNf",
        "outputId": "ad7ccc32-ba9e-4346-d0e1-228ac61eb7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Standard deviation of column_2: 0.2805991083901862\n"
          ]
        }
      ],
      "source": [
        "column2_std = df1['column_2'].std()\n",
        "print(\"\\nStandard deviation of column_2:\", column2_std)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uMDLX7kGQJI1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_4_k8PrR9sB"
      },
      "source": [
        "Q5. Replace the data present in the second row of column, â€˜column_2â€™ by a string variable then find the mean of column, column_2.\n",
        "\n",
        "If you are getting errors in executing it then explain why.\n",
        "\n",
        "[Hint: To replace the data use df1.loc[] and equate this to string data of your choice.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrBNrE23SE93"
      },
      "source": [
        "A5. Step 1: Replacing the Second Row of column_2 with a String"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5akp7dNlRnvs",
        "outputId": "79854db1-0658-48a3-fb23-9e47048c75c2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-8-ef7a38b2490d>:1: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value 'string_value' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
            "  df1.loc[2, 'column_2'] = \"string_value\"\n"
          ]
        }
      ],
      "source": [
        "df1.loc[2, 'column_2'] = \"string_value\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FF08kaQGSKx6"
      },
      "source": [
        "We are replacing the second row (index 2) of 'column_2' with a string.\n",
        "\n",
        "Step 2: Trying to Calculate the Mean of column_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "xWT6RCdvSH2X",
        "outputId": "a053bb6a-5a1a-4cbb-a029-6dc855b09cc0"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for +: 'float' and 'str'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-88c58f5b4369>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_column2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'column_2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of column_2:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_column2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6547\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6548\u001b[0m     ):\n\u001b[0;32m-> 6549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6551\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"median\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12418\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12419\u001b[0m     ) -> Series | float:\n\u001b[0;32m> 12420\u001b[0;31m         return self._stat_function(\n\u001b[0m\u001b[1;32m  12421\u001b[0m             \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12422\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12375\u001b[0m         \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"skipna\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_allowed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 12377\u001b[0;31m         return self._reduce(\n\u001b[0m\u001b[1;32m  12378\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  12379\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6455\u001b[0m                     \u001b[0;34m\"with non-numeric dtypes.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6456\u001b[0m                 )\n\u001b[0;32m-> 6457\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6459\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"any\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/numpy/_core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     50\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     51\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'float' and 'str'"
          ]
        }
      ],
      "source": [
        "mean_column2 = df1['column_2'].mean()\n",
        "print(\"Mean of column_2:\", mean_column2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6U9pGpGSXMl"
      },
      "source": [
        "## What Will Happen?\n",
        "ðŸ”¥ Error!\n",
        "The mean() function will raise an error because 'column_2' now contains a string, and mean can only be calculated on numeric values.\n",
        "\n",
        "Expected Error Message\n",
        "```\n",
        "TypeError: unsupported operand type(s) for +: 'float' and 'str'\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crvHu05nSd7F"
      },
      "source": [
        "**Explanation:**\n",
        "\n",
        "Pandas tries to compute the mean, but encounters a string value in 'column_2'.\n",
        "\n",
        "Since arithmetic operations (+ and /) between numbers and strings are not allowed, it throws a TypeError."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlrxPzrcSPe2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzPZKeJ4Sj_c"
      },
      "source": [
        "# How to Fix the Error?\n",
        "\n",
        "Solution 1: Convert the Column to Numeric (Ignoring Errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Suj-B27TSlnt",
        "outputId": "5459bccc-7d6b-401b-80bf-c5521fea6e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of column_2 after conversion: 0.40822028785282444\n"
          ]
        }
      ],
      "source": [
        "df1['column_2'] = pd.to_numeric(df1['column_2'], errors='coerce')\n",
        "mean_column2 = df1['column_2'].mean()\n",
        "print(\"Mean of column_2 after conversion:\", mean_column2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myIpR05KSouV"
      },
      "source": [
        "ðŸ”¹ pd.to_numeric(errors='coerce') converts non-numeric values into NaN, allowing the mean calculation to proceed.\n",
        "\n",
        "Solution 2: Remove Non-Numeric Rows Before Calculating Mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FJENOdFSnAk",
        "outputId": "44bed4ce-c982-4d64-b79c-a3dcd3200c01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean of column_2 after filtering: 0.40822028785282444\n"
          ]
        }
      ],
      "source": [
        "mean_column2 = df1[df1['column_2'].apply(lambda x: isinstance(x, (int, float)))]['column_2'].mean()\n",
        "print(\"Mean of column_2 after filtering:\", mean_column2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSyADJY6Sssu"
      },
      "source": [
        "ðŸ”¹ This method filters out non-numeric values before computing the mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyl8mW2hSqXt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kFCXfOoSyh6"
      },
      "source": [
        "Q6. What do you understand about the windows function in pandas and list the types of windows functions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEXVDcG1S3xA"
      },
      "source": [
        "A6. **What is a Window Function in Pandas?**\n",
        "\n",
        "A window function in Pandas is used for performing calculations over a rolling or expanding window of data points. These functions are useful in time-series analysis, moving averages, smoothing, and trend detection.\n",
        "\n",
        "They work by sliding over the data (row-wise), performing operations on a subset of rows within the specified window."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYfnrkmvSzt8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieJ--gC2S-lG"
      },
      "source": [
        "### Types of Window Functions in Pandas\n",
        "\n",
        "1.) **Rolling Window Functions (rolling())**\n",
        "\n",
        "a.) Performs operations on a fixed-size moving window.\n",
        "\n",
        "b.) Example: Moving Average, Moving Sum, Moving Standard Deviation.\n",
        "\n",
        "Example Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zctju07TGjt",
        "outputId": "09e8b60f-02ab-41ab-92c4-7c41ffc554e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Values  Moving_Avg\n",
            "0      10         NaN\n",
            "1      20         NaN\n",
            "2      30        20.0\n",
            "3      40        30.0\n",
            "4      50        40.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = {'Values': [10, 20, 30, 40, 50]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# 3-point Moving Average\n",
        "df['Moving_Avg'] = df['Values'].rolling(window=3).mean()\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxM1LvMYTLCy"
      },
      "source": [
        "2.) **Expanding Window Functions (expanding())**\n",
        "\n",
        "a.) Expands the window size dynamically from the start to the current row.\n",
        "\n",
        "Example: Cumulative Sum, Cumulative Mean.\n",
        "\n",
        "Example Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff8CLpAyTIFV",
        "outputId": "1c664a18-1031-4883-8343-81f42bcfe70c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Values  Moving_Avg  Cumulative_Avg\n",
            "0      10         NaN            10.0\n",
            "1      20         NaN            15.0\n",
            "2      30        20.0            20.0\n",
            "3      40        30.0            25.0\n",
            "4      50        40.0            30.0\n"
          ]
        }
      ],
      "source": [
        "df['Cumulative_Avg'] = df['Values'].expanding().mean()\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMrFrF9gTYeN"
      },
      "source": [
        "3.) **Exponentially Weighted Window Functions (ewm())**\n",
        "\n",
        "a.) Assigns more weight to recent values, useful in time series smoothing.\n",
        "\n",
        "Example: Exponentially Weighted Moving Average (EWMA).\n",
        "\n",
        "Example Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om0DJz9GTWD8",
        "outputId": "a76910af-ee42-496c-fd4a-3c2a772c291f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Values  Moving_Avg  Cumulative_Avg    EWMA\n",
            "0      10         NaN            10.0  10.000\n",
            "1      20         NaN            15.0  15.000\n",
            "2      30        20.0            20.0  22.500\n",
            "3      40        30.0            25.0  31.250\n",
            "4      50        40.0            30.0  40.625\n"
          ]
        }
      ],
      "source": [
        "df['EWMA'] = df['Values'].ewm(span=3, adjust=False).mean()\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHUOBBL-TiId"
      },
      "source": [
        "4.) **GroupBy Window Functions**\n",
        "\n",
        "a.) Applies window functions within groups.\n",
        "\n",
        "Example: Rolling Mean within Categories.\n",
        "\n",
        "Example Code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSN0VGwhTeqM",
        "outputId": "1dcdcd9a-4510-440c-ce5a-71efad5dd374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Values  Moving_Avg  Cumulative_Avg    EWMA Group  Grouped_Rolling_Avg\n",
            "0      10         NaN            10.0  10.000     A                  NaN\n",
            "1      20         NaN            15.0  15.000     A                 15.0\n",
            "2      30        20.0            20.0  22.500     B                  NaN\n",
            "3      40        30.0            25.0  31.250     B                 35.0\n",
            "4      50        40.0            30.0  40.625     B                 45.0\n"
          ]
        }
      ],
      "source": [
        "df['Group'] = ['A', 'A', 'B', 'B', 'B']\n",
        "df['Grouped_Rolling_Avg'] = df.groupby('Group')['Values'].rolling(2).mean().reset_index(0, drop=True)\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L-aPR2bTriQ"
      },
      "source": [
        "### Key Takeaways\n",
        "\n",
        "âœ… rolling() â†’ Fixed-size moving window\n",
        "\n",
        "âœ… expanding() â†’ Expanding window (cumulative operations)\n",
        "\n",
        "âœ… ewm() â†’ Exponentially weighted window\n",
        "\n",
        "âœ… groupby().rolling() â†’ Rolling window within groups"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOrk24wATnPd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsU5n8HIT1vX"
      },
      "source": [
        "Q7. Write a code to print only the current month and year at the time of answering this question.\n",
        "\n",
        "[Hint: Use pandas.datetime function]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KS8TS_J1T2kV",
        "outputId": "d7c0612d-ac88-4384-908b-e3a856386622"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current Month: 3\n",
            "Current Year: 2025\n"
          ]
        }
      ],
      "source": [
        "# A7.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Get current date\n",
        "current_date = pd.to_datetime(\"today\")\n",
        "\n",
        "# Extract month and year\n",
        "current_month = current_date.month\n",
        "current_year = current_date.year\n",
        "\n",
        "print(f\"Current Month: {current_month}\")\n",
        "print(f\"Current Year: {current_year}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QISXUxjVT9xl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytjZzuXZUHpL"
      },
      "source": [
        "Q8. Write a Python program that takes in two dates as input (in the format YYYY-MM-DD) and\n",
        "calculates the difference between them in days, hours, and minutes using Pandas time delta. The program should prompt the user to enter the dates and display the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6Xa23RxUJOk",
        "outputId": "f05900cf-1e57-411e-9f1e-159941f17e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the first date (YYYY-MM-DD): 1999-05-08\n",
            "Enter the second date (YYYY-MM-DD): 2025-03-23\n",
            "Difference: 9451 days, 0 hours, 0 minutes\n"
          ]
        }
      ],
      "source": [
        "# A8.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Take user input for two dates\n",
        "date1 = input(\"Enter the first date (YYYY-MM-DD): \")\n",
        "date2 = input(\"Enter the second date (YYYY-MM-DD): \")\n",
        "\n",
        "# Convert strings to datetime\n",
        "date1 = pd.to_datetime(date1)\n",
        "date2 = pd.to_datetime(date2)\n",
        "\n",
        "# Calculate the difference\n",
        "time_diff = abs(date2 - date1)\n",
        "\n",
        "# Extract days, hours, and minutes\n",
        "days = time_diff.days\n",
        "hours = time_diff.seconds // 3600\n",
        "minutes = (time_diff.seconds % 3600) // 60\n",
        "\n",
        "# Display the result\n",
        "print(f\"Difference: {days} days, {hours} hours, {minutes} minutes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dG1eHj4FUSYF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPHIngcsUp4v"
      },
      "source": [
        "Q9. Write a Python program that reads a CSV file containing categorical data and converts a specified column to a categorical data type. The program should prompt the user to enter the file path, column name, and category order, and then display the sorted data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu34c50rUr-r",
        "outputId": "7727d127-27f9-42a2-9c94-b253caaed4cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Available columns in the dataset: ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value']\n",
            "\n",
            "Unique values in the column: [606.0, 277.0, 495.0, 11.0, 237.0, 204.0, 218.0, 441.0, 599.0, 603.0, 261.0, 138.0, 170.0, 659.0, 331.0, 50.0, 107.0, 595.0, 199.0, 1258.0, 255.0, 305.0, 561.0, 480.0, 940.0, 225.0, 979.0, 402.0, 1539.0, 901.0, 229.0, 500.0, 619.0, 2651.0, 169.0, 728.0, 419.0, 190.0, 985.0, 287.0, 429.0, 226.0, 294.0, 1672.0, 242.0, 329.0, 350.0, 1593.0, 1780.0, 122.0, 464.0, 366.0, 335.0, 510.0, 468.0, 282.0, 586.0, 139.0, 285.0, 307.0, 404.0, 729.0, 1123.0, 228.0, 702.0, 378.0, 387.0, 515.0, 384.0, 274.0, 234.0, 679.0, 834.0, 957.0, 147.0, 375.0, 351.0, 1377.0, 467.0, 558.0, 182.0, 581.0, 222.0, 321.0, 173.0, 275.0, 850.0, 479.0, 302.0, 519.0, 317.0, 416.0, 1231.0, 456.0, 496.0, 407.0, 569.0, 364.0, 417.0, 301.0, 273.0, 434.0, 443.0, 414.0, 81.0, 236.0, 425.0, 73.0, 1007.0, 536.0, 930.0, 759.0, 484.0, 377.0, 596.0, 320.0, 703.0, 671.0, 270.0, 491.0, 391.0, 593.0, 640.0, 472.0, 1235.0, 543.0, 1178.0, 149.0, 230.0, 390.0, 347.0, 216.0, 685.0, 339.0, 349.0, 787.0, 731.0, 389.0, 663.0, 247.0, 300.0, 625.0, 773.0, 602.0, 662.0, 342.0, 367.0, 680.0, 243.0, 534.0, 314.0, 643.0, 362.0, 1061.0, 289.0, 422.0, 653.0, 551.0, 435.0, 114.0, 741.0, 215.0, 975.0, 1019.0, 217.0, 485.0, 158.0, 532.0, 297.0, 368.0, 497.0, 578.0, 121.0, 254.0, 1735.0, 264.0, 360.0, 133.0, 268.0, 521.0, 568.0, 1038.0, 693.0, 447.0, 807.0, 174.0, 47.0, 579.0, 376.0, 418.0, 55.0, 306.0, 231.0, 159.0, 647.0, 446.0, 501.0, 408.0, 361.0, 835.0, 517.0, 482.0, 118.0, 658.0, 516.0, 127.0, 758.0, 859.0, 1283.0, 1304.0, 795.0, 952.0, 475.0, 772.0, 244.0, 695.0, 439.0, 332.0, 260.0, 224.0, 380.0, 410.0, 105.0, 557.0, 493.0, 193.0, 1767.0, 449.0, 373.0, 340.0, 299.0, 594.0, 269.0, 1113.0, 357.0, 450.0, 873.0, 481.0, 178.0, 219.0, 721.0, 448.0, 298.0, 896.0, 2221.0, 458.0, 137.0, 1439.0, 423.0, 71.0, 452.0, 628.0, 535.0, 371.0, 623.0, 343.0, 1316.0, 511.0, 486.0, 327.0, 288.0, 251.0, 951.0, 279.0, 888.0, 381.0, 292.0, 548.0, 514.0, 3293.0, 345.0, 1390.0, 184.0, 587.0, 575.0, 492.0, 267.0, 308.0, 252.0, 498.0, 1450.0, 437.0, 396.0, 783.0, 304.0, 584.0, 1015.0, 155.0, 909.0, 431.0, 100.0, 733.0, 280.0, 374.0, 328.0, 525.0, 424.0, 359.0, 385.0, 1010.0, 1107.0, 403.0, 70.0, 641.0, 524.0, 706.0, 908.0, 393.0, 540.0, 379.0, 455.0, 322.0, 171.0, 956.0, 319.0, 573.0, 409.0, 700.0, 673.0, 2157.0, 352.0, 239.0, 866.0, 88.0, 112.0, 597.0, 942.0, 705.0, 356.0, 466.0, 987.0, 119.0, 1118.0, 800.0, 315.0, 919.0, 460.0, 341.0, 211.0, 660.0, 370.0, 839.0, 580.0, 696.0, 761.0, 697.0, 132.0, 538.0, 622.0, 469.0, 205.0, 432.0, 313.0, 544.0, 954.0, 257.0, 316.0, 401.0, 1405.0, 355.0, 54.0, 326.0, 221.0, 256.0, 187.0, 841.0, 57.0, 474.0, 372.0, 430.0, 531.0, 577.0, 618.0, 241.0, 982.0, 176.0, 712.0, 571.0, 392.0, 739.0, 539.0, 369.0, 399.0, 26.0, 249.0, 1888.0, 293.0, 722.0, 504.0, 324.0, 683.0, 554.0, 334.0, 181.0, 806.0, 542.0, 506.0, 1226.0, 518.0, 420.0, 180.0, 1511.0, 505.0, 142.0, 530.0, 214.0, 17.0, 1247.0, 794.0, 415.0, 69.0, 588.0, 284.0, 84.0, 200.0, 684.0, 194.0, 462.0, 812.0, 110.0, 354.0, 411.0, 737.0, 445.0, 550.0, 162.0, 192.0, 814.0, 646.0, 175.0, 865.0, 365.0, 489.0, 1273.0, 333.0, 676.0, 765.0, 271.0, 1035.0, 30.0, 576.0, 459.0, 730.0, 1027.0, 779.0, 136.0, 823.0, 154.0, 442.0, 457.0, 246.0, 499.0, 98.0, 9.0, 763.0, 980.0, 642.0, 135.0, 290.0, 2009.0, 195.0, 630.0, 428.0, 134.0, 276.0, 7.0, 168.0, 692.0, 283.0, 687.0, 1079.0, 281.0, 453.0, 465.0, 717.0, 400.0, 86.0, 993.0, 1055.0, 1056.0, 572.0, 76.0, 615.0, 507.0, 478.0, 212.0, 394.0, 311.0, 620.0, 363.0, 87.0, 386.0, 892.0, 397.0, 235.0, 129.0, 817.0, 395.0, 1189.0, 842.0, 185.0, 678.0, 14.0, 398.0, 560.0, 51.0, 3.0, 15.0, 922.0, 614.0, 780.0, 1566.0, 611.0, 638.0, 338.0, 433.0, 209.0, 406.0, 66.0, 977.0, 286.0, 227.0, 1020.0, 654.0, 789.0, 145.0, 704.0, 348.0, 890.0, 723.0, 626.0, 910.0, 629.0, 150.0, 197.0, 62.0, 206.0, 25.0, 1217.0, 312.0, 1001.0, 296.0, 509.0, 1047.0, 738.0, 202.0, 1472.0, 1245.0, 513.0, 278.0, 715.0, 926.0, 966.0, 769.0, 471.0, 116.0, 527.0, 1333.0, 144.0, 146.0, 1694.0, 27.0, 650.0, 1286.0, 1112.0, 1374.0, 2964.0, 126.0, 1005.0, 857.0, 157.0, 191.0, 612.0, 109.0, 565.0, 797.0, 318.0, 894.0, 1159.0, 440.0, 470.0, 2127.0, 183.0, 591.0, 245.0, 91.0, 503.0, 291.0, 210.0, 1096.0, 4855.0, 552.0, 166.0, 830.0, 743.0, 188.0, 106.0, 945.0, 21.0, 461.0, 1174.0, 556.0, 742.0, 874.0, 533.0, 248.0, 463.0, 130.0, 1057.0, 41.0, 849.0, 1014.0, 601.0, 563.0, 90.0, 49.0, 272.0, 1496.0, 113.0, 537.0, 198.0, 631.0, 826.0, 562.0, 745.0, 295.0, 265.0, 528.0, 487.0, 788.0, 80.0, 189.0, 82.0, 508.0, 1875.0, 1222.0, 67.0, 1066.0, 724.0, 876.0, 259.0, 131.0, 1210.0, 262.0, 522.0, 488.0, 2.0, 451.0, 736.0, 778.0, 838.0, 657.0, 546.0, 1162.0, 213.0, 616.0, 310.0, 740.0, 266.0, 3958.0, 666.0, 958.0, 436.0, 969.0, 1165.0, 263.0, 454.0, 523.0, 600.0, 774.0, 1131.0, 694.0, 915.0, 802.0, 973.0, 747.0, 309.0, 89.0, 208.0, 303.0, 163.0, 986.0, 608.0, 13.0, 555.0, 151.0, 250.0, 172.0, 636.0, 358.0, 1546.0, 120.0, 153.0, 567.0, 798.0, 108.0, 726.0, 1092.0, 621.0, 633.0, 1503.0, 476.0, 843.0, 613.0, 732.0, 337.0, 959.0, 648.0, 2392.0, 808.0, 644.0, 914.0, 123.0, 719.0, 634.0, 141.0, 553.0, 559.0, 941.0, 223.0, 777.0, 382.0, 1004.0, 893.0, 1119.0, 8.0, 1196.0, 1046.0, 336.0, 2040.0, 1051.0, 165.0, 1012.0, 323.0, 412.0, 346.0, 125.0, 720.0, 978.0, 1703.0, 955.0, 871.0, 681.0, 164.0, 233.0, 23.0, 1634.0, 179.0, 512.0, 96.0, 1116.0, 143.0, 1166.0, 152.0, 1939.0, 744.0, 1906.0, 34.0, 56.0, 953.0, 388.0, 617.0, 427.0, 253.0, 545.0, 751.0, 574.0, 1229.0, 31.0, 238.0, 48.0, 1299.0, 22.0, 1028.0, 709.0, 58.0, 609.0, 669.0, 2230.0, 775.0, 714.0, 4930.0, 1087.0, 592.0, 847.0, 1146.0, 426.0, 490.0, 1212.0, 160.0, 353.0, 1140.0, 904.0, 668.0, 2043.0, 3252.0, 994.0, 1041.0, 438.0, 735.0, 589.0, 39.0, 1265.0, 564.0, 1298.0, 768.0, 932.0, 879.0, 344.0, 935.0, 103.0, 682.0, 1444.0, 405.0, 1045.0, 1415.0, 711.0, 760.0, 413.0, 852.0, 604.0, 1029.0, 383.0, 330.0, 1399.0, 1021.0, 855.0, 1397.0, 665.0, 770.0, 1470.0, 991.0, 1073.0, 1076.0, 177.0, 1997.0, 161.0, 1505.0, 716.0, 325.0, 675.0, 764.0, 1049.0, 784.0, 831.0, 1239.0, 1138.0, 186.0, 887.0, 1394.0, 529.0, 115.0, 258.0, 746.0, 1318.0, 801.0, 102.0, 477.0, 828.0, 582.0, 796.0, 526.0, 664.0, 627.0, 832.0, 2357.0, 68.0, 1335.0, 2019.0, 203.0, 937.0, 1106.0, 984.0, 4176.0, 201.0, 651.0, 947.0, 686.0, 1300.0, 1060.0, 792.0, 520.0, 749.0, 1199.0, 1500.0, 45.0, 1135.0, 998.0, 884.0, 649.0, 652.0, 483.0, 94.0, 148.0, 936.0, 566.0, 707.0, 782.0, 793.0, 754.0, 10.0, 655.0, 1840.0, 74.0, 1139.0, 1789.0, 691.0, 95.0, 1680.0, 1184.0, 24.0, 1722.0, 1220.0, 1327.0, 40.0, 1322.0, 541.0, 65.0, 1268.0, 1068.0, 725.0, 864.0, 1198.0, 688.0, 72.0, 104.0, 1761.0, 583.0, 502.0, 29.0, 1494.0, 753.0, 912.0, 1811.0, 1257.0, 661.0, 1387.0, 570.0, 585.0, 962.0, 598.0, 220.0, 444.0, 1499.0, 3197.0, 1644.0, 1009.0, 710.0, 1078.0, 1985.0, 1187.0, 1227.0, 756.0, 590.0, 1250.0, 632.0, 815.0, 16.0, 785.0, 701.0, 790.0, 1313.0, 61.0, 1520.0, 1058.0, 232.0, 1216.0, 836.0, 196.0, 1486.0, 1267.0, 881.0, 1006.0, 813.0, 1031.0, 2335.0, 883.0, 1451.0, 1781.0, 156.0, 1844.0, 960.0, 1429.0, 93.0, 1421.0, 766.0, 905.0, 78.0, 762.0, 639.0, 32.0, 1527.0, 698.0, 950.0, 1025.0, 870.0, 1919.0, 1000.0, 858.0, 827.0, 1064.0, 1395.0, 997.0, 421.0, 624.0, 840.0, 12.0, 1043.0, 961.0, 494.0, 1091.0, 944.0, 1482.0, 1458.0, 821.0, 1972.0, 207.0, 549.0, 689.0, 1115.0, 1158.0, 963.0, 885.0, 92.0, 607.0, 1036.0]\n"
          ]
        }
      ],
      "source": [
        "# A9.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# User input for file path\n",
        "file_path = input(\"Enter the CSV file path: \")\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display available columns\n",
        "print(\"\\nAvailable columns in the dataset:\", df.columns.tolist())\n",
        "\n",
        "# User input for the column name\n",
        "column_name = input(\"\\nEnter the column name to convert to categorical: \")\n",
        "\n",
        "# Check if the column exists\n",
        "if column_name not in df.columns:\n",
        "    print(\"Error: Column not found in the dataset.\")\n",
        "else:\n",
        "    # Get unique values from the column\n",
        "    unique_values = df[column_name].dropna().unique().tolist()\n",
        "    print(\"\\nUnique values in the column:\", unique_values)\n",
        "\n",
        "    # User input for category order\n",
        "    category_order = input(\"\\nEnter the category order separated by commas: \").split(\",\")\n",
        "\n",
        "    # Convert the column to categorical type with specified order\n",
        "    df[column_name] = pd.Categorical(df[column_name], categories=category_order, ordered=True)\n",
        "\n",
        "    # Sort data by the categorical column\n",
        "    sorted_df = df.sort_values(by=column_name)\n",
        "\n",
        "    # Display the sorted data\n",
        "    print(\"\\nSorted Data:\")\n",
        "    print(sorted_df.head())\n",
        "\n",
        "    # Optional: Save the sorted file\n",
        "    sorted_df.to_csv(\"sorted_output.csv\", index=False)\n",
        "    print(\"\\nSorted data saved as 'sorted_output.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YR9rymKyU0Vu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q10. Write a Python program that reads a CSV file containing sales data for different products and visualizes the data using a stacked bar chart to show the sales of each product category over time. The program should prompt the user to enter the file path and display the chart."
      ],
      "metadata": {
        "id": "gpGVLgfzrj-c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A10.\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# User input for the file path\n",
        "file_path = input(\"Enter the CSV file path: \")\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display available columns\n",
        "print(\"\\nAvailable columns in the dataset:\", df.columns.tolist())\n",
        "\n",
        "# Checking if required columns exist\n",
        "required_columns = ['Date', 'Product_Category', 'Sales']\n",
        "if not all(col in df.columns for col in required_columns):\n",
        "    print(f\"Error: The dataset must contain the columns {required_columns}.\")\n",
        "else:\n",
        "    # Convert 'Date' column to datetime\n",
        "    df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "    # Pivot the DataFrame to get sales data for each category over time\n",
        "    sales_pivot = df.pivot_table(index='Date', columns='Product_Category', values='Sales', aggfunc='sum')\n",
        "\n",
        "    # Plot the stacked bar chart\n",
        "    sales_pivot.plot(kind='bar', stacked=True, figsize=(12, 6), colormap='viridis')\n",
        "\n",
        "    # Formatting the plot\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Sales')\n",
        "    plt.title('Sales of Each Product Category Over Time')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.legend(title=\"Product Category\")\n",
        "\n",
        "    # Display the chart\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_Nt7gA2rmm8",
        "outputId": "0c335efe-84a6-4d87-cc42-ca99dc8900da"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the CSV file path: /content/sample_data/mnist_test.csv\n",
            "\n",
            "Available columns in the dataset: ['7', '0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '0.10', '0.11', '0.12', '0.13', '0.14', '0.15', '0.16', '0.17', '0.18', '0.19', '0.20', '0.21', '0.22', '0.23', '0.24', '0.25', '0.26', '0.27', '0.28', '0.29', '0.30', '0.31', '0.32', '0.33', '0.34', '0.35', '0.36', '0.37', '0.38', '0.39', '0.40', '0.41', '0.42', '0.43', '0.44', '0.45', '0.46', '0.47', '0.48', '0.49', '0.50', '0.51', '0.52', '0.53', '0.54', '0.55', '0.56', '0.57', '0.58', '0.59', '0.60', '0.61', '0.62', '0.63', '0.64', '0.65', '0.66', '0.67', '0.68', '0.69', '0.70', '0.71', '0.72', '0.73', '0.74', '0.75', '0.76', '0.77', '0.78', '0.79', '0.80', '0.81', '0.82', '0.83', '0.84', '0.85', '0.86', '0.87', '0.88', '0.89', '0.90', '0.91', '0.92', '0.93', '0.94', '0.95', '0.96', '0.97', '0.98', '0.99', '0.100', '0.101', '0.102', '0.103', '0.104', '0.105', '0.106', '0.107', '0.108', '0.109', '0.110', '0.111', '0.112', '0.113', '0.114', '0.115', '0.116', '0.117', '0.118', '0.119', '0.120', '0.121', '0.122', '0.123', '0.124', '0.125', '0.126', '0.127', '0.128', '0.129', '0.130', '0.131', '0.132', '0.133', '0.134', '0.135', '0.136', '0.137', '0.138', '0.139', '0.140', '0.141', '0.142', '0.143', '0.144', '0.145', '0.146', '0.147', '0.148', '0.149', '0.150', '0.151', '0.152', '0.153', '0.154', '0.155', '0.156', '0.157', '0.158', '0.159', '0.160', '0.161', '0.162', '0.163', '0.164', '0.165', '0.166', '0.167', '0.168', '0.169', '0.170', '0.171', '0.172', '0.173', '0.174', '0.175', '0.176', '0.177', '0.178', '0.179', '0.180', '0.181', '0.182', '0.183', '0.184', '0.185', '0.186', '0.187', '0.188', '0.189', '0.190', '0.191', '0.192', '0.193', '0.194', '0.195', '0.196', '0.197', '0.198', '0.199', '0.200', '0.201', '84', '185', '159', '151', '60', '36', '0.202', '0.203', '0.204', '0.205', '0.206', '0.207', '0.208', '0.209', '0.210', '0.211', '0.212', '0.213', '0.214', '0.215', '0.216', '0.217', '0.218', '0.219', '0.220', '0.221', '0.222', '0.223', '222', '254', '254.1', '254.2', '254.3', '241', '198', '198.1', '198.2', '198.3', '198.4', '198.5', '198.6', '198.7', '170', '52', '0.224', '0.225', '0.226', '0.227', '0.228', '0.229', '0.230', '0.231', '0.232', '0.233', '0.234', '0.235', '67', '114', '72', '114.1', '163', '227', '254.4', '225', '254.5', '254.6', '254.7', '250', '229', '254.8', '254.9', '140', '0.236', '0.237', '0.238', '0.239', '0.240', '0.241', '0.242', '0.243', '0.244', '0.245', '0.246', '0.247', '0.248', '0.249', '0.250', '0.251', '0.252', '17', '66', '14', '67.1', '67.2', '67.3', '59', '21', '236', '254.10', '106', '0.253', '0.254', '0.255', '0.256', '0.257', '0.258', '0.259', '0.260', '0.261', '0.262', '0.263', '0.264', '0.265', '0.266', '0.267', '0.268', '0.269', '0.270', '0.271', '0.272', '0.273', '0.274', '0.275', '0.276', '83', '253', '209', '18', '0.277', '0.278', '0.279', '0.280', '0.281', '0.282', '0.283', '0.284', '0.285', '0.286', '0.287', '0.288', '0.289', '0.290', '0.291', '0.292', '0.293', '0.294', '0.295', '0.296', '0.297', '0.298', '0.299', '22', '233', '255', '83.1', '0.300', '0.301', '0.302', '0.303', '0.304', '0.305', '0.306', '0.307', '0.308', '0.309', '0.310', '0.311', '0.312', '0.313', '0.314', '0.315', '0.316', '0.317', '0.318', '0.319', '0.320', '0.321', '0.322', '0.323', '129', '254.11', '238', '44', '0.324', '0.325', '0.326', '0.327', '0.328', '0.329', '0.330', '0.331', '0.332', '0.333', '0.334', '0.335', '0.336', '0.337', '0.338', '0.339', '0.340', '0.341', '0.342', '0.343', '0.344', '0.345', '0.346', '59.1', '249', '254.12', '62', '0.347', '0.348', '0.349', '0.350', '0.351', '0.352', '0.353', '0.354', '0.355', '0.356', '0.357', '0.358', '0.359', '0.360', '0.361', '0.362', '0.363', '0.364', '0.365', '0.366', '0.367', '0.368', '0.369', '0.370', '133', '254.13', '187', '5', '0.371', '0.372', '0.373', '0.374', '0.375', '0.376', '0.377', '0.378', '0.379', '0.380', '0.381', '0.382', '0.383', '0.384', '0.385', '0.386', '0.387', '0.388', '0.389', '0.390', '0.391', '0.392', '0.393', '9', '205', '248', '58', '0.394', '0.395', '0.396', '0.397', '0.398', '0.399', '0.400', '0.401', '0.402', '0.403', '0.404', '0.405', '0.406', '0.407', '0.408', '0.409', '0.410', '0.411', '0.412', '0.413', '0.414', '0.415', '0.416', '0.417', '126', '254.14', '182', '0.418', '0.419', '0.420', '0.421', '0.422', '0.423', '0.424', '0.425', '0.426', '0.427', '0.428', '0.429', '0.430', '0.431', '0.432', '0.433', '0.434', '0.435', '0.436', '0.437', '0.438', '0.439', '0.440', '0.441', '75', '251', '240', '57', '0.442', '0.443', '0.444', '0.445', '0.446', '0.447', '0.448', '0.449', '0.450', '0.451', '0.452', '0.453', '0.454', '0.455', '0.456', '0.457', '0.458', '0.459', '0.460', '0.461', '0.462', '0.463', '0.464', '19', '221', '254.15', '166', '0.465', '0.466', '0.467', '0.468', '0.469', '0.470', '0.471', '0.472', '0.473', '0.474', '0.475', '0.476', '0.477', '0.478', '0.479', '0.480', '0.481', '0.482', '0.483', '0.484', '0.485', '0.486', '0.487', '3', '203', '254.16', '219', '35', '0.488', '0.489', '0.490', '0.491', '0.492', '0.493', '0.494', '0.495', '0.496', '0.497', '0.498', '0.499', '0.500', '0.501', '0.502', '0.503', '0.504', '0.505', '0.506', '0.507', '0.508', '0.509', '0.510', '38', '254.17', '254.18', '77', '0.511', '0.512', '0.513', '0.514', '0.515', '0.516', '0.517', '0.518', '0.519', '0.520', '0.521', '0.522', '0.523', '0.524', '0.525', '0.526', '0.527', '0.528', '0.529', '0.530', '0.531', '0.532', '0.533', '31', '224', '254.19', '115', '1', '0.534', '0.535', '0.536', '0.537', '0.538', '0.539', '0.540', '0.541', '0.542', '0.543', '0.544', '0.545', '0.546', '0.547', '0.548', '0.549', '0.550', '0.551', '0.552', '0.553', '0.554', '0.555', '0.556', '133.1', '254.20', '254.21', '52.1', '0.557', '0.558', '0.559', '0.560', '0.561', '0.562', '0.563', '0.564', '0.565', '0.566', '0.567', '0.568', '0.569', '0.570', '0.571', '0.572', '0.573', '0.574', '0.575', '0.576', '0.577', '0.578', '0.579', '61', '242', '254.22', '254.23', '52.2', '0.580', '0.581', '0.582', '0.583', '0.584', '0.585', '0.586', '0.587', '0.588', '0.589', '0.590', '0.591', '0.592', '0.593', '0.594', '0.595', '0.596', '0.597', '0.598', '0.599', '0.600', '0.601', '0.602', '121', '254.24', '254.25', '219.1', '40', '0.603', '0.604', '0.605', '0.606', '0.607', '0.608', '0.609', '0.610', '0.611', '0.612', '0.613', '0.614', '0.615', '0.616', '0.617', '0.618', '0.619', '0.620', '0.621', '0.622', '0.623', '0.624', '0.625', '121.1', '254.26', '207', '18.1', '0.626', '0.627', '0.628', '0.629', '0.630', '0.631', '0.632', '0.633', '0.634', '0.635', '0.636', '0.637', '0.638', '0.639', '0.640', '0.641', '0.642', '0.643', '0.644', '0.645', '0.646', '0.647', '0.648', '0.649', '0.650', '0.651', '0.652', '0.653', '0.654', '0.655', '0.656', '0.657', '0.658', '0.659', '0.660', '0.661', '0.662', '0.663', '0.664', '0.665', '0.666', '0.667']\n",
            "Error: The dataset must contain the columns ['Date', 'Product_Category', 'Sales'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2JCfPD51r3dV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q11. You are given a CSV file containing student data that includes the student ID and their test score. Write a Python program that reads the CSV file, calculates the mean, median, and mode of the test scores, and\n",
        "displays the results in a table.\n",
        "\n",
        "The program should do the following:\n",
        "\n",
        "a.)  Prompt the user to enter the file path of the CSV file containing the student data.\n",
        "\n",
        "b.) Read the CSV file into a Pandas DataFrame.\n",
        "\n",
        "c.) Calculate the mean, median, and mode of the test scores using Pandas toolsR\n",
        "\n",
        "d.) Display the mean, median, and mode in a table.\n",
        "\n",
        "Assume the CSV file contains the following columns\n",
        "\n",
        "a.) Student ID: The ID of the studentR\n",
        "\n",
        "b.) Test Score: The score of the student's test.\n",
        "\n",
        "Example usage of the program:\n",
        "Enter the file path of the CSV file containing the student data: student_data.csv\n",
        "\n",
        "```\n",
        "+-----------+--------+\n",
        "| Statistic | Value |\n",
        "+-----------+--------+\n",
        "| Mean | 79.6 |\n",
        "| Median | 82 |\n",
        "| Mode | 85, 90 |\n",
        "+-----------+--------+\n",
        "\n",
        "Assume that the CSV file student_data.csv contains the following data:\n",
        "Student ID,Test Score\n",
        "1,85\n",
        "2,90\n",
        "3,80\n",
        "4,75\n",
        "5,85\n",
        "6,82\n",
        "7,78\n",
        "8,85\n",
        "9,90\n",
        "10,85\n",
        "```\n",
        "\n",
        "The program should calculate the mean, median, and mode of the test scores and display the results in a table."
      ],
      "metadata": {
        "id": "c0gQ817EsQ6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A11.\n",
        "\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Prompt user for file path\n",
        "file_path = input(\"Enter the file path of the CSV file containing the student data: \")\n",
        "\n",
        "# Read CSV into a Pandas DataFrame\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Ensure required columns exist\n",
        "if \"Test Score\" not in df.columns:\n",
        "    print(\"Error: The dataset must contain a 'Test Score' column.\")\n",
        "else:\n",
        "    # Calculate statistics\n",
        "    mean_score = df[\"Test Score\"].mean()\n",
        "    median_score = df[\"Test Score\"].median()\n",
        "    mode_score = df[\"Test Score\"].mode().tolist()\n",
        "\n",
        "    # Convert mode to a comma-separated string if multiple values exist\n",
        "    mode_str = \", \".join(map(str, mode_score))\n",
        "\n",
        "    # Create a table to display results\n",
        "    results = [\n",
        "        [\"Mean\", round(mean_score, 2)],\n",
        "        [\"Median\", median_score],\n",
        "        [\"Mode\", mode_str]\n",
        "    ]\n",
        "\n",
        "    # Print results in table format\n",
        "    print(\"\\n\" + tabulate(results, headers=[\"Statistic\", \"Value\"], tablefmt=\"grid\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47LqxdTXs4-8",
        "outputId": "cc96295d-301d-419e-a6c3-6c44367db4a7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the file path of the CSV file containing the student data: /content/sample_data/testscore.csv\n",
            "\n",
            "+-------------+---------+\n",
            "| Statistic   |   Value |\n",
            "+=============+=========+\n",
            "| Mean        |    83.5 |\n",
            "+-------------+---------+\n",
            "| Median      |    85   |\n",
            "+-------------+---------+\n",
            "| Mode        |    85   |\n",
            "+-------------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t5wUxWSkG3wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LVksYgOCKm2P"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}