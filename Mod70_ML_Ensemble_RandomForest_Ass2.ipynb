{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module70 Ensemble Techniques Ass2"
      ],
      "metadata": {
        "id": "wGOo-T-gUlL9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. How does bagging reduce overfitting in decision trees?\n",
        "\n",
        "A1. Bagging reduces overfitting in decision trees by:\n",
        "\n",
        "1.) **Reducing variance:** Decision trees are high-variance models. Bagging averages the predictions of multiple trees, which stabilizes and smooths the predictions, reducing overfitting.\n",
        "\n",
        "2.) **Bootstrap sampling:** Each tree is trained on a different bootstrap sample, introducing diversity in the ensemble and preventing any single tree from dominating the predictions.\n",
        "\n",
        "3.) **Majority voting/averaging:** By aggregating the predictions (e.g., via majority voting in classification or averaging in regression), bagging reduces the influence of noisy, overfitted predictions from individual trees."
      ],
      "metadata": {
        "id": "WvXc7sOuQ0dX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VyIDl_BQda2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. What are the advantages and disadvantages of using different types of base learners in bagging?\n",
        "\n",
        "\n",
        "A2.\n",
        "\n",
        "# Advantages:\n",
        "\n",
        "1.) **Flexibility:** Bagging can be applied to any model (e.g., decision trees, SVMs).\n",
        "\n",
        "2.) **Improved performance:** Using unstable models (like decision trees) benefits the most from bagging because their high variance can be significantly reduced.\n",
        "\n",
        "3.) **Robustness:** Combining weak learners increases overall accuracy and stability.\n",
        "\n",
        "\n",
        "# Disadvantages:\n",
        "\n",
        "1.) **Computational cost:** Bagging with complex base learners (e.g., SVMs) can be computationally expensive.\n",
        "\n",
        "2.) **Bias limitations:** If the base learners have high bias (e.g., linear regression for non-linear data), bagging will not improve accuracy significantly.\n",
        "\n",
        "3.) **Overfitting stable models:** Models with low variance (e.g., KNN) may not benefit much from bagging and can result in computational inefficiency."
      ],
      "metadata": {
        "id": "tjqhhUJDREr-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RDl8QqGVRzbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does the choice of base learner affect the bias-variance tradeoff in bagging?\n",
        "\n",
        "A3. The choice of base learner affect the bias-variance tradeoff in bagging is like this -\n",
        "\n",
        "1.) **High-variance learners (e.g., decision trees):** Bagging works best with these because it reduces variance without significantly increasing bias. This leads to better generalization.\n",
        "\n",
        "2.) **High-bias learners (e.g., linear regression):** Bagging has limited effect because it cannot reduce the bias inherent in the base model.\n",
        "\n",
        "3.) **Balanced learners (e.g., moderately pruned trees):** Bagging can still improve performance but may provide diminishing returns compared to high-variance learners.\n",
        "\n",
        "Choosing the right base learner depends on the dataset and the specific tradeoff between bias and variance required for the task."
      ],
      "metadata": {
        "id": "i7zm3r6GR33k"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mKWo9MezSVa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Can bagging be used for both classification and regression tasks? How does it differ in each case?\n",
        "\n",
        "A4. Yes, bagging can be used for both classification and regression tasks.\n",
        "\n",
        "## Classification:\n",
        "\n",
        "Aggregation is done through **majority voting**: The class predicted by most of the base learners is the final prediction.\n",
        "\n",
        "Example: Random Forest for classification.\n",
        "\n",
        "\n",
        "## Regression:\n",
        "\n",
        "Aggregation is done through **averaging**: The final prediction is the mean of the predictions from all base learners.\n",
        "\n",
        "Example: Random Forest for regression.\n",
        "\n",
        "The main difference lies in how predictions are aggregated (voting vs. averaging)."
      ],
      "metadata": {
        "id": "xifvvbtKSYW9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7sOeP3VPSqUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is the role of ensemble size in bagging? How many models should be included in the ensemble?\n",
        "\n",
        "A5. The ensemble size in bagging determines:\n",
        "\n",
        "1.) **Accuracy:** Larger ensembles usually lead to better predictions, up to a certain point.\n",
        "\n",
        "2.) **Stability:** Larger ensembles make predictions less sensitive to individual model variations.\n",
        "\n",
        "3.) **Diminishing returns:** Beyond a certain ensemble size, additional models provide little improvement in performance.\n",
        "\n",
        "## How many models to include?\n",
        "\n",
        "1.) A common choice is 100-500 models for most tasks.\n",
        "\n",
        "2.) Empirically, the ensemble size is determined by:\n",
        "    \n",
        "a.) Computational resources: Larger ensembles require more training time.\n",
        "    \n",
        "b.) Performance plateau: Stop increasing the size when performance stabilizes on a validation set."
      ],
      "metadata": {
        "id": "ShLCymPtS4hC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mp-_e4_aTaSO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Can you provide an example of a real-world application of bagging in machine learning?\n",
        "\n",
        "A6. Here is an example of Bagging in ML -\n",
        "\n",
        "# Example: Fraud Detection\n",
        "\n",
        "In fraud detection systems, bagging is commonly used with decision trees (e.g., Random Forest) to identify fraudulent transactions.\n",
        "\n",
        "1.) **Problem:** Fraudulent activities often exhibit complex patterns, making it difficult for a single model to capture all nuances.\n",
        "\n",
        "\n",
        "2.) **Why bagging?**\n",
        "\n",
        "a.) Reduces variance and overfitting caused by noisy patterns in transaction data.\n",
        "\n",
        "b.) Improves accuracy and robustness by combining diverse predictions from multiple decision trees.\n",
        "\n",
        "\n",
        "3.) **Result:** Enhanced ability to detect fraud with fewer false positives and false negatives.\n",
        "\n",
        "\n",
        "## Other real-world applications of bagging include:\n",
        "\n",
        "1.) Customer churn prediction.\n",
        "\n",
        "2.) Medical diagnosis systems.\n",
        "\n",
        "3.) Weather forecasting."
      ],
      "metadata": {
        "id": "ZFGObsKfTj14"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j7ImPUBtUGbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-xoSCRbUiiO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}