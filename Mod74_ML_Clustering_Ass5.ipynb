{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module74 Clustering Ass 5"
      ],
      "metadata": {
        "id": "3-k9VMQoTkKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is a contingency matrix, and how is it used to evaluate the performance of a classification model?"
      ],
      "metadata": {
        "id": "nkIMVj2wTiRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. A contingency matrix (or confusion matrix) is a table used to evaluate the performance of a classification model by comparing predicted labels with actual labels.\n",
        "\n",
        "For a binary classification problem, it looks like this:\n",
        "\n",
        "```\n",
        "Actual \\ Predicted\tPositive (P)\tNegative (N)\n",
        "Positive (P)\tTrue Positive (TP)\tFalse Negative (FN)\n",
        "Negative (N)\tFalse Positive (FP)\tTrue Negative (TN)\n",
        "\n",
        "```\n",
        "\n",
        "Usage:\n",
        "\n",
        "1.) Calculates performance metrics like accuracy, precision, recall, F1-score.\n",
        "\n",
        "2.) Identifies misclassification patterns.\n"
      ],
      "metadata": {
        "id": "KXbIjDsZPULP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BhnHCc0pUMsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How is a pair confusion matrix different from a regular confusion matrix, and why might it be useful in certain situations?"
      ],
      "metadata": {
        "id": "qtv2VEu0Tmfj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2. A pair confusion matrix is used in clustering evaluation and compares pairs of samples rather than individual class labels. It is used to evaluate pairwise agreements between true and predicted labels.\n",
        "\n",
        "```\n",
        "Pairs\tSame Cluster (Predicted)\tDifferent Clusters (Predicted)\n",
        "Same Class (True)\tTrue Positive (TP)\tFalse Negative (FN)\n",
        "Different Class (True)\tFalse Positive (FP)\tTrue Negative (TN)\n",
        "```\n",
        "\n",
        "Why Useful?\n",
        "\n",
        "Used in unsupervised learning where labels are not predefined.\n",
        "\n",
        "Helps compute Rand Index, Adjusted Rand Index (ARI) for clustering performance.\n",
        "\n",
        "Avoids over-reliance on individual label assignments.\n"
      ],
      "metadata": {
        "id": "lnxWeiihPl8P"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DhJNq3o5UNcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. What is an extrinsic measure in the context of natural language processing, and how is it typically\n",
        "used to evaluate the performance of language models?"
      ],
      "metadata": {
        "id": "avHH3zbQToZs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. An extrinsic measure evaluates a model based on its performance in real-world tasks rather than internal characteristics.\n",
        "\n",
        "Examples in NLP:\n",
        "\n",
        "1.) Machine Translation: BLEU, METEOR (evaluated on end-user translation quality).\n",
        "\n",
        "2.) Speech Recognition: Word Error Rate (WER).\n",
        "\n",
        "3.) Text Summarization: ROUGE Score (based on summary quality).\n",
        "\n",
        "### Usage:\n",
        "\n",
        "1.) Measures real-world impact.\n",
        "\n",
        "2.) Used in downstream tasks like chatbots, translation, etc.\n"
      ],
      "metadata": {
        "id": "k4pPmq_1Pz7t"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j4Pjoit1UOSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. What is an intrinsic measure in the context of machine learning, and how does it differ from an\n",
        "extrinsic measure?"
      ],
      "metadata": {
        "id": "rBxhKa9rTqGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4. An intrinsic measure evaluates a model based on its internal properties rather than its effect on an external task.\n",
        "\n",
        "Examples:\n",
        "\n",
        "1.) **Word Embeddings:** Cosine similarity between words.\n",
        "\n",
        "2.) **Language Models:** Perplexity (measures probability of text sequences).\n",
        "\n",
        "3.) **Clustering:** Silhouette Score (internal cluster quality).\n",
        "\n",
        "### Difference:\n",
        "\n",
        "```\n",
        "Feature\t| Intrinsic Measure              |\tExtrinsic Measure\n",
        "---------------------------------------------------------------------------\n",
        "Focus\t  | Internal properties            | Task performance\n",
        "---------------------------------------------------------------------------\n",
        "Examples   |Perplexity, Silhouette Score    | BLEU, ROUGE, Accuracy\n",
        "---------------------------------------------------------------------------\n",
        "Use Case   |\tModel development           |\tReal-world evaluation\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "_O3vyJ1-QAIR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4znaJxojUO8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. What is the purpose of a confusion matrix in machine learning, and how can it be used to identify\n",
        "strengths and weaknesses of a model?"
      ],
      "metadata": {
        "id": "nNpfMiDYTshN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5. The purpose of a confusion matrix is to provide a detailed breakdown of true vs. false predictions in a classification model.\n",
        "\n",
        "### How It Identifies Strengths and Weaknesses?\n",
        "\n",
        "1.) **High TP & TN** → Model performs well.\n",
        "\n",
        "2.) **High FP** → Model misclassifies negatives (bad precision).\n",
        "\n",
        "3.) **High FN** → Model fails to detect positives (bad recall).\n",
        "\n",
        "4.) **Imbalanced classes** → Accuracy may be misleading, so use F1-score."
      ],
      "metadata": {
        "id": "Gv-7lglPRqIT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NQF6kw2fUP4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. What are some common intrinsic measures used to evaluate the performance of unsupervised\n",
        "learning algorithms, and how can they be interpreted?"
      ],
      "metadata": {
        "id": "Lve_ZCMWTvB9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A6. Intrinsic measures evaluate cluster quality without external labels.\n",
        "\n",
        "```\n",
        "Metric\t                              |        Interpretation\n",
        "___________________________________________________________________________________________________________\n",
        "\n",
        "Silhouette Score\t            | Measures how well data points fit into clusters (closer to 1 is better).\n",
        "\n",
        "------------------------------------------------------------------------------------------------------------\n",
        "Davies-Bouldin Index\t            | Measures cluster separation and compactness (lower is better).\n",
        "------------------------------------------------------------------------------------------------------------\n",
        "Calinski-Harabasz Index\t             | Higher values mean better-defined clusters.\n",
        "------------------------------------------------------------------------------------------------------------\n",
        "Within-Cluster Sum of Squares (WCSS)\t| Measures cluster compactness (lower is better).\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "1po4Ve5kR9PB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D1ZzvgCTUQp0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. What are some limitations of using accuracy as a sole evaluation metric for classification tasks, and\n",
        "how can these limitations be addressed?"
      ],
      "metadata": {
        "id": "EO3gxDL8TxMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A7. Some limitations of using accuracy as a sole evaluation metric for classification tasks, and how can these limitations be addressed by following:\n",
        "\n",
        "### Limitations of Accuracy:\n",
        "\n",
        "1.) Imbalanced Data: Accuracy is misleading if one class dominates (e.g., 95% accuracy but all predictions are one class).\n",
        "\n",
        "2.) False Negatives Matter: In medical diagnoses, FN (missed disease) is critical.\n",
        "\n",
        "3.) Doesn’t Consider Class Importance: Some misclassifications are more costly than others.\n",
        "\n",
        "### Solutions:\n",
        "1.) Use Precision, Recall, F1-score instead.\n",
        "\n",
        "2.) Compute ROC-AUC for imbalanced datasets.\n",
        "\n",
        "3.) Use Confusion Matrix for detailed analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "hLQdUEt1TWR6"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oeRzJLb2UR9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ho_WgzywT_fw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
