{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mod85 Optimizers Assignment"
      ],
      "metadata": {
        "id": "KIJqr5ZtxbSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective: Assess understanding of optimization algorithms in artificial neural networks. Evaluate the application and comparison of different optimizers. Enhance knowledge of optimizers' impact on model convergence and performance.\n",
        "\n"
      ],
      "metadata": {
        "id": "RcrwUKEQwJN5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZLkQd1NQxnOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Understanding Optimizer"
      ],
      "metadata": {
        "id": "6_3iCWlrEe4w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is the role of optimization algorithms in artificial neural networks? Why are they necessary?"
      ],
      "metadata": {
        "id": "rEfi3QDoEpYB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. Optimization algorithms are the brains behind the learning in neural networks ‚Äî they take error signals and turn them into smarter models by fine-tuning parameters in the right way.\n",
        "\n",
        "### Role of Optimization Algorithms in ANNs -\n",
        "\n",
        "#### **1.) Minimizing the Loss Function**\n",
        "\n",
        "- Neural networks learn by minimizing a loss function, which measures how far off the network‚Äôs predictions are from the actual target values.\n",
        "\n",
        "- Optimization algorithms help adjust the model‚Äôs parameters (weights and biases) to reduce this error.\n",
        "\n",
        "#### **2.) Guiding Weight Updates**\n",
        "\n",
        "- At each iteration (epoch), an optimizer uses gradients (calculated via backpropagation) to determine:\n",
        "\n",
        "- **Direction:** Which way to change the weights\n",
        "\n",
        "- **Magnitude:** How much to change them\n",
        "\n",
        "#### **3.) Efficient Convergence**\n",
        "\n",
        "- Good optimizers help the model converge faster and more reliably to an optimal (or near-optimal) set of weights, reducing training time and improving performance.\n",
        "\n",
        "#### **4.) Avoiding Pitfalls**\n",
        "\n",
        "Advanced optimizers help avoid:\n",
        "\n",
        "- **Local minima:** Getting stuck in bad spots in the loss landscape.\n",
        "\n",
        "- **Saddle points:** Flat regions that stall training.\n",
        "\n",
        "- **Exploding/vanishing gradients**\n",
        "\n",
        "\n",
        "## Why Are They Necessary?\n",
        "\n",
        "Without optimization algorithms:\n",
        "\n",
        "- A neural network wouldn't learn at all ‚Äî weights would stay random.\n",
        "\n",
        "- The model wouldn't be able to adapt to data, generalize patterns, or improve predictions.\n",
        "\n",
        "- Manually adjusting millions of weights in a deep neural net would be impossible and extremely inefficient.\n",
        "\n",
        "\n",
        "### Common Optimization Algorithms are -\n",
        "\n",
        "1. ) Gradient Descent (and variants like Batch, Stochastic, and Mini-Batch)\n",
        "\n",
        "2. ) Momentum\n",
        "\n",
        "3. ) RMSprop\n",
        "\n",
        "4. ) Adam (widely used due to its adaptive learning rate and momentum features)"
      ],
      "metadata": {
        "id": "_HVeajXeFawX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rum5h8yvxnSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Explain the concept of gradient descent and its variants. Discuss their differences and tradeoffs in terms of convergence speed and memory requirements."
      ],
      "metadata": {
        "id": "9XmKT9FUGs1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2. Gradient Descent is an algorithm used to minimize a loss function by iteratively updating the model's parameters in the direction that reduces error (i.e., the negative of the gradient).\n",
        "\n",
        "Update Rule:\n",
        "```\n",
        "ùúÉ = ùúÉ ‚àí ùúÇ ‚ãÖ ‚àáùêΩ(ùúÉ)\n",
        "\n",
        "```\n",
        "Œ∏: Model parameters (weights/biases)\n",
        "\n",
        "Œ∑ (eta): Learning rate (step size)\n",
        "\n",
        "‚àáJ(Œ∏): Gradient of the loss function with respect to the parameters.\n",
        "\n",
        "## Variants of Gradient Descent\n",
        "\n",
        "#### 1.) Batch Gradient Descent\n",
        "\n",
        "Uses the entire dataset to compute gradients for every step.\n",
        "\n",
        "- **Pros:**\n",
        "\n",
        "  - a.) Stable and accurate gradient direction.\n",
        "\n",
        "  - b.) Works well with smaller datasets.\n",
        "\n",
        "- **Cons:**\n",
        "\n",
        "  - a.) Very slow with large datasets.\n",
        "\n",
        "  - b.) Requires high memory to load full data in each iteration.\n",
        "\n",
        "\n",
        "Convergence Speed: üîΩ Slow,\n",
        "\n",
        "Memory: üîº High\n",
        "\n",
        "\n",
        "### 2.) Stochastic Gradient Descent (SGD)\n",
        "\n",
        "Uses one training example at each step.\n",
        "\n",
        "- **Pros:**\n",
        "\n",
        "  - a.) Fast updates ‚Äî useful for large datasets.\n",
        "\n",
        "  - b.) Can escape local minima due to its randomness.\n",
        "\n",
        "- **Cons:**\n",
        "\n",
        "  - a.) Noisy updates cause fluctuation ‚Äî might not settle near the minimum.\n",
        "\n",
        "  - b.) Harder to converge smoothly.\n",
        "\n",
        "Convergence Speed: üîº Fast (per update), but may require more steps.\n",
        "\n",
        "Memory: üîΩ Very Low\n",
        "\n",
        "\n",
        "### 3.) Mini-Batch Gradient Descent\n",
        "Uses a small batch of data (e.g., 32 or 128 samples) at each step.\n",
        "\n",
        "- **Pros:**\n",
        "\n",
        "  - a.) Best of both worlds ‚Äî faster than batch, more stable than SGD.\n",
        "\n",
        "  - b.) Efficient with modern hardware (e.g., GPUs).\n",
        "\n",
        "- **Cons:**\n",
        "\n",
        "  - a.) Still introduces some noise (less than SGD).\n",
        "\n",
        "  - b.) Needs tuning of batch size for best results.\n",
        "\n",
        "Convergence Speed: Balanced\n",
        "\n",
        "Memory: Moderate\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pYnm9elaG-iv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ESj3tLzRGyR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Describe the challenges associated with traditional gradient descent optimization methods (e.g., slow convergence, local minima). How do modern optimizers address these challenges."
      ],
      "metadata": {
        "id": "C0N_I8qAgiVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. Challenges of Traditional Gradient Descent\n",
        "Traditional gradient descent methods (like vanilla SGD or batch GD) work well in theory, but they face several practical challenges, especially with complex models like neural networks.\n",
        "\n",
        "1.) Slow Convergence\n",
        "\n",
        "- In flat regions (called plateaus) or when gradients are small (i.e., vanishing gradients), the optimizer makes tiny updates.\n",
        "\n",
        "- This slows down learning ‚Äî training takes forever.\n",
        "\n",
        "2.) Local Minima / Saddle Points\n",
        "\n",
        "- In high-dimensional space, models can get stuck in local minima or saddle points (flat regions with zero slope).\n",
        "\n",
        "- The optimizer doesn't know which direction to go, so it just gets ‚Äústuck.‚Äù\n",
        "\n",
        "3.) Oscillations in Narrow Valleys\n",
        "\n",
        "- Sometimes the loss surface looks like a narrow ravine ‚Äî steep in one direction, flat in another.\n",
        "\n",
        "- Gradient descent keeps jumping side to side, slowing progress toward the bottom.\n",
        "\n",
        "4.) Learning Rate Sensitivity\n",
        "\n",
        "- **Too small:** training is slow.\n",
        "\n",
        "- **Too large:** risk of overshooting the minimum or diverging entirely.\n",
        "\n",
        "- A fixed learning rate often doesn‚Äôt work well throughout training.\n",
        "\n",
        "# How Modern Optimizers Solve These Problems\n",
        "\n",
        "Modern optimizers were created to tackle these exact issues. Here‚Äôs how they help:\n",
        "\n",
        "1.) **Momentum**\n",
        "\n",
        "- Speeds up learning and smooths out the path.\n",
        "\n",
        "- Adds ‚Äúvelocity‚Äù to the updates so the model accelerates through plateaus and doesn‚Äôt get stuck.\n",
        "\n",
        "- Helps avoid zig-zagging in narrow valleys.\n",
        "\n",
        "- Think of rolling a ball downhill ‚Äî it picks up speed and doesn't stop at small bumps.\n",
        "\n",
        "2) **Adaptive Learning Rates**\n",
        "\n",
        "- Different learning rates for each parameter.\n",
        "\n",
        "- Optimizers like AdaGrad, RMSprop, and Adam adjust learning rates automatically based on past gradients.\n",
        "\n",
        "- Helps deal with vanishing gradients or frequent updates to certain parameters.\n",
        "\n",
        "3.) **Adam Optimizer: Best of All Worlds**\n",
        "\n",
        "- Momentum + Adaptive Learning Rates\n",
        "\n",
        "- Adam (Adaptive Moment Estimation) is the most popular optimizer.\n",
        "\n",
        "### *It keeps track of:*\n",
        "\n",
        "1. ) First moment (mean of gradients) ‚Üí like momentum\n",
        "\n",
        "2. ) Second moment (variance of gradients) ‚Üí for adaptive scaling\n",
        "\n",
        "3. )  Fast convergence, works well out of the box, handles noise, flat regions, and sharp curves effectively.\n",
        "\n",
        "\n",
        "# TL;DR\n",
        "Traditional gradient descent is simple but struggles with real-world deep learning tasks. Modern optimizers like Momentum, RMSprop, and especially Adam overcome these by:\n",
        "\n",
        "1. ) Speeding up training,\n",
        "\n",
        "2. ) Avoiding traps like saddle points or local minima,\n",
        "\n",
        "3. ) Adjusting learning rates dynamically."
      ],
      "metadata": {
        "id": "M0UkwTBfg-nm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UIiiojhfgo73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.Discuss the concepts of momentum and learning rate in the context of optimization algorithms. How do they impact convergence and model performance?"
      ],
      "metadata": {
        "id": "Q5-cPGTVjFDg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4.\n",
        "## 1. Learning Rate (Œ∑)\n",
        "\n",
        "The learning rate determines how big a step the optimizer takes when updating model parameters during training.\n",
        "\n",
        "Update Rule (basic SGD):\n",
        "```\n",
        "Œ∏ = Œ∏ ‚àí Œ∑ ‚ãÖ ‚àáJ(Œ∏)\n",
        "```\n",
        "Small Œ∑: Tiny steps ‚Üí slow convergence, but stable.\n",
        "\n",
        "Large Œ∑: Big steps ‚Üí faster convergence, but risk of overshooting or even diverging.\n",
        "\n",
        "\n",
        "### Impact on Model Performance:\n",
        "\n",
        "1. ) If Œ∑ is too small, the model might never reach the optimum.\n",
        "\n",
        "2. ) If Œ∑ is too large, the loss might oscillate or increase ‚Äî causing the model to fail to converge.\n",
        "\n",
        "### Solution:\n",
        "\n",
        "Modern optimizers (like Adam) use adaptive learning rates, so different parameters can learn at different speeds ‚Äî improving performance and stability.\n",
        "\n",
        "------------------------------------------------------------------------------------------------\n",
        "## 2. Momentum\n",
        "\n",
        "- Momentum helps the model remember the past gradients and builds speed in directions where the gradient consistently points the same way.\n",
        "\n",
        "- Imagine pushing a ball down a hill ‚Äî momentum keeps it moving faster in the same direction.\n",
        "\n",
        "### Update Rule (Momentum version of SGD):\n",
        "```\n",
        "Vt‚Äã = Œ≥Vt‚àí1‚Äã + Œ∑ ‚ãÖ ‚àáJ(Œ∏)\n",
        "\n",
        "Œ∏ = Œ∏ ‚àí Vt\n",
        "\n",
        "```\n",
        "\n",
        "Vt : velocity (accumulated gradient)\n",
        "\n",
        "Œ≥ (gamma) : momentum factor (typically around 0.9)\n",
        "\n",
        "## Impact on Convergence:\n",
        "\n",
        "1. ) Speeds up training, especially on flat surfaces or ravines.\n",
        "\n",
        "2. ) Reduces oscillations by smoothing updates across steps.\n",
        "\n",
        "3. ) Helps the model get out of small local minima and avoid zig-zagging.\n",
        "\n",
        "## Best Practice Tips\n",
        "\n",
        "1. ) Start with a default learning rate (like 0.001 for Adam or 0.01 for SGD), then tune based on performance.\n",
        "\n",
        "2. ) Use momentum (typically 0.9) with SGD for deeper models.\n",
        "\n",
        "3. ) Consider learning rate scheduling (decaying over time) to help models fine-tune in later stages.\n",
        "\n",
        "\n",
        "##  TL;DR\n",
        "\n",
        "1. ) Learning Rate controls how fast the model learns.\n",
        "\n",
        "2. ) Momentum controls how smoothly the model learns.\n",
        "\n",
        "3. ) Together, they play a crucial role in achieving fast, stable, and effective training.\n"
      ],
      "metadata": {
        "id": "1HfiWn5sBOcn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T-wji3CtjHtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHo0c_a0Dvzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Optimizer Technique"
      ],
      "metadata": {
        "id": "xGr0LCGkDa6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.Explain the concept of Stochastic Gradient Descent (SGD) and its advantages compared to traditional gradient descent. Discuss its limitations and scenarios where it is most suitable.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4_PrvrBVDYgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5. Traditional (Batch) Gradient Descent:\n",
        "Uses all the training data to compute the gradient before each update.\n",
        "\n",
        "Update rule:\n",
        "```\n",
        "Œ∏ = Œ∏ ‚àí Œ∑ ‚ãÖ ‚àáJ(Œ∏)\n",
        "```\n",
        "Very accurate but slow and memory-intensive, especially with large datasets.\n",
        "\n",
        "\n",
        "##  SGD (Stochastic Gradient Descent):\n",
        "Instead of the full dataset, SGD uses a single randomly picked training example to compute the gradient and update the weights.\n",
        "```\n",
        "Œ∏ = Œ∏ ‚àí Œ∑ ‚ãÖ ‚àáJ(Œ∏; x(i), y(i))\n",
        "```\n",
        "\n",
        "Here, ( x(i) , y(i) ) is one data point.\n",
        "\n",
        "\"Stochastic\" means **random**, so each step is based on a random sample ‚Äî leading to noisy, but fast updates.\n",
        "\n",
        "## Advantages of SGD\n",
        "\n",
        "1. ) Faster updates - It updates weights after every sample ‚Üí much quicker iterations.\n",
        "\n",
        "2. ) Low memory usage - Doesn‚Äôt need to load the full dataset into memory.\n",
        "\n",
        "3. ) Better for online learning - Can be updated continuously as new data comes in.\n",
        "\n",
        "4. ) Can escape local minima - The noise in updates sometimes helps jump out of shallow minima or saddle points.\n",
        "\n",
        "## Limitations of SGD\n",
        "\n",
        "1. ) Noisy updates- The random nature makes the path to convergence bumpy.\n",
        "\n",
        "2. ) Slower final convergence - It might take longer to settle near the minimum, oscillating around it.\n",
        "\n",
        "3. ) Sensitive to learning rate - Choosing the wrong learning rate can cause divergence or very slow learning.\n",
        "\n",
        "4. ) No guarantee of convergence - Especially without techniques like momentum or decay.\n",
        "\n",
        "## Best Use Cases for SGD\n",
        "\n",
        "1. ) Large-scale datasets (e.g., millions of images or text samples)\n",
        "\n",
        "2. ) Online learning: models that learn in real time as new data arrives\n",
        "\n",
        "3. ) Deep learning tasks like image classification, NLP, etc.\n",
        "\n",
        "4. ) When quick model iteration is more important than perfect convergence.\n",
        "\n",
        "\n",
        "## Common Enhancements to SGD\n",
        "\n",
        "1. ) To deal with its instability, several techniques are commonly used:\n",
        "\n",
        "2. ) Mini-batch SGD: Uses a small batch (e.g., 32 or 64 samples) instead of one ‚Üí balances speed and stability.\n",
        "\n",
        "3. ) Momentum: Helps smooth the path toward the minimum.\n",
        "\n",
        "4. ) Learning rate scheduling: Gradually reduces the learning rate over time.\n",
        "\n",
        "5. ) Adaptive optimizers: Like Adam or RMSprop, built on top of SGD to fix its weaknesses.\n",
        "\n",
        "## TL;DR\n",
        "\n",
        "1. ) SGD = Fast, memory-efficient, slightly noisy updates.\n",
        "\n",
        "2. ) It‚Äôs great for large-scale or online learning tasks, but may need momentum or learning rate tricks for best performance.\n",
        "\n",
        "3. ) Think of it as quick and scrappy compared to accurate but slow traditional gradient descent."
      ],
      "metadata": {
        "id": "n8v0rrDuEBSv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4aiKgdsyDuNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6.Describe the concept of Adam optimizer and how it combines momentum and adaptive learning rates."
      ],
      "metadata": {
        "id": "Zk7_uXOsDqbm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A6. Adam stands for Adaptive Moment Estimation.\n",
        "\n",
        "It‚Äôs an optimization algorithm that combines the benefits of two other methods:\n",
        "\n",
        "1. ) Momentum (to smooth updates)\n",
        "\n",
        "2. ) Adaptive learning rates (like in RMSProp)\n",
        "\n",
        "Adam is designed to handle:\n",
        "\n",
        "- Noisy gradients\n",
        "\n",
        "- Sparse data\n",
        "\n",
        "- Non-stationary objectives (changing loss landscapes)\n",
        "\n",
        "## How Adam Works\n",
        "At each time step t, Adam maintains two moving averages:\n",
        "\n",
        "ùëöt : the first moment (mean of gradients) ‚Üí acts like momentum.\n",
        "\n",
        "vt : the second moment (uncentered variance of gradients) ‚Üí used for adaptive learning rate.\n",
        "\n",
        "\n",
        "### Update steps:\n",
        "\n",
        "1. ) Compute gradient\n",
        "```gt‚Äã = ‚àáJ(Œ∏t)```\n",
        "\n",
        "2. ) Update biased moment estimates:\n",
        "\n",
        "```\n",
        "mt‚Äã = Œ≤1‚Äã * m(t‚àí1)‚Äã +(1‚àíŒ≤1) * gt‚Äã  [momentum]\n",
        "```\n",
        "\n",
        "```\n",
        "vt‚Äã = Œ≤2‚Äã* v(t‚àí1)‚Äã +(1‚àíŒ≤2‚Äã) * gt^2  [RMS-like scaling]‚Äã\n",
        "```\n",
        "\n",
        "3.) Correct the bias (especially early in training):\n",
        "```\n",
        "^\n",
        "mt = mt / [1 ‚àí (Œ≤1)^t]‚Äã‚Äã\n",
        "\n",
        "```\n",
        "\n",
        "```\n",
        "^\n",
        "vt = vt / [1 ‚àí (Œ≤2)^t]‚Äã‚Äã\n",
        "\n",
        "```\n",
        "\n",
        "4.) Update the parameters:\n",
        "\n",
        "```\n",
        "Œ∏(t+1)‚Äã = Œ∏(t‚Äã) ‚àí Œ∑ ‚ãÖ [mt^/ (sqrt(vt^ + ùúñ))‚Äã]\n",
        "\n",
        "```\n",
        "\n",
        "Œ∑: learning rate (default = 0.001)\n",
        "\n",
        "ùõΩ1 : decay rate for momentum (default = 0.9)\n",
        "\n",
        "ùõΩ2 : decay rate for RMS (default = 0.999)\n",
        "\n",
        "œµ: small constant to prevent division by zero (default = 1e-8)\n",
        "\n",
        "\n",
        "## Advantages of ADAM:\n",
        "\n",
        "1. ) Momentum(via mt) - Speeds up training and smooths updates.\n",
        "\n",
        "2. ) Adaptive learning rate(via vt) - Automatically adjusts the learning rate for each parameter.\n",
        "\n",
        "3. ) Bias correction - Prevents instability in early iterations.\n",
        "\n",
        "4. ) Works well out-of-the-box - Minimal tuning needed for most problems.\n",
        "\n",
        "5. ) Efficient - Low memory use, fast convergence.\n",
        "\n",
        "###  Limitations of Adam\n",
        "\n",
        "1. ) Can sometimes overfit or stop improving too early (not always the best generalizer).\n",
        "\n",
        "2. ) Slightly less robust on certain convex problems compared to SGD with momentum.\n",
        "\n",
        "3. ) More hyperparameters (though defaults often work well).\n",
        "\n",
        "## Use Cases\n",
        "\n",
        "- a. ) Deep learning tasks (CNNs, RNNs, Transformers)\n",
        "\n",
        "- b. ) Noisy problems (e.g., reinforcement learning)\n",
        "\n",
        "- c. ) Sparse gradients (e.g., NLP, embeddings)\n",
        "\n",
        "\n",
        "## TL;DR\n",
        "\n",
        "1. ) Adam = Momentum + Adaptive Learning Rates.\n",
        "\n",
        "2. ) It tracks both the average of past gradients (like momentum) and the average of their squared values (like RMSProp).\n",
        "\n",
        "3. ) Result: fast, stable, and effective optimization with minimal tweaking.\n"
      ],
      "metadata": {
        "id": "uHq66N8rlAfp"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ka048nNSDp52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.Explain the concept of RMSprop optimizer and how it addresses the challenges of adaptive learning rates. Compare it with Adam and discuss their relative strengths and weaknesses."
      ],
      "metadata": {
        "id": "n5WsB6ZxDnXi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A7. RMSprop (Root Mean Square Propagation) is an adaptive learning rate optimization algorithm designed to overcome the limitations of standard gradient descent, especially slow convergence and oscillations in steep valleys.\n",
        "\n",
        "### Key idea:\n",
        "RMSprop adjusts the learning rate individually for each parameter by dividing the gradient by a running average of the magnitudes of recent gradients.\n",
        "\n",
        "### How RMSprop Works\n",
        "\n",
        "At each step t:\n",
        "\n",
        "1. ) Compute the gradient:\n",
        "```\n",
        "gt‚Äã = ‚àáŒ∏‚Äã J(Œ∏t‚Äã)\n",
        "```\n",
        "\n",
        "2. ) Update the moving average of squared gradients:\n",
        "```\n",
        "E[(g)^2]t = Œ≤ * E[(g)^2]t-1 + (1-Œ≤) * (gt)^2\n",
        "```\n",
        "\n",
        "3. ) Update the parameters:\n",
        "\n",
        "```\n",
        "Œ∏(t+1) = Œ∏(t) - [Œ∑ / sqrt(E[(g)^2]t + œµ)] * gt   , where\n",
        "\n",
        "‚ÄãŒ∑: learning rate\n",
        "\n",
        "Œ≤: decay factor (typically ~0.9)\n",
        "\n",
        "œµ: small constant for numerical stability (e.g., 1ùëí‚àí8)\n",
        "```\n",
        "\n",
        "## How RMSprop Solves Adaptive Learning Rate Issues\n",
        "1. ) Parameters with frequent updates (large gradients) get smaller learning rates.\n",
        "\n",
        "2. ) Parameters with infrequent updates get larger learning rates.\n",
        "\n",
        "3. ) This helps reduce oscillations and speeds up convergence, especially in non-convex loss surfaces.\n",
        "\n",
        "\n",
        "## TL;DR\n",
        "1. ) RMSprop is great at smoothing out learning using per-parameter adaptive learning rates.\n",
        "\n",
        "2. ) Adam takes it further by adding momentum and bias correction, making it more powerful but also slightly more complex.\n",
        "\n",
        "3. ) Both are excellent choices ‚Äî Adam is more popular, but RMSprop can shine in RNNs and certain niche tasks."
      ],
      "metadata": {
        "id": "2QN4RFW4pl-a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MAlyZ0daDn-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Applying Optimizer"
      ],
      "metadata": {
        "id": "tBMtFcHWroUk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jvddDSSgrpza"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.Implement SGD, Adam, and RMSprop optimizers in a deep learning model using a framework of your choice. Train the model on a suitable dataset and compare their impact on model convergence and performance."
      ],
      "metadata": {
        "id": "Ze9ufrxGrrok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A8.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load MNIST Dataset\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.MNIST(root= './data', train= True, download= True, transform= transform)\n",
        "test_dataset = datasets.MNIST(root= './data', train = False, download= True, transform= transform)\n",
        "\n",
        "train_loader= DataLoader(train_dataset, batch_size = 64, shuffle= True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1000, shuffle= False)\n",
        "\n",
        "# 2. Define the Neural Network\n",
        "class SimpleNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SimpleNN, self).__init__()\n",
        "    self.fc1 = nn.Linear(28 *28, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28 *28)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return self.fc3(x)\n",
        "\n",
        "\n",
        "# 3. Training function\n",
        "def train_model(optimizer_type= 'SGD', epochs= 5):\n",
        "  model = SimpleNN()\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "  optimizer = {\n",
        "      'SGD': torch.optim.SGD(model.parameters(), lr= 0.01),\n",
        "      'Adam': torch.optim.Adam(model.parameters(), lr= 0.001),\n",
        "      'RMSprop': torch.optim.RMSprop(model.parameters(), lr= 0.001)\n",
        "  }[optimizer_type]\n",
        "\n",
        "  train_losses = []\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "    for batch_idx, (data,target) in enumerate(train_loader):\n",
        "      optimizer.zero_grad()\n",
        "      output = model(data)\n",
        "      loss = criterion(output, target)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      total_loss +=loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    train_losses.append(avg_loss)\n",
        "    print(f\"{optimizer_type} - Epoch {epoch+1}, Loss: {avg_loss:.4f}\")\n",
        "  return train_losses\n",
        "\n",
        "\n",
        "# 4. Compare optimizers\n",
        "sgd_loss = train_model('SGD', epochs= 10)\n",
        "adam_loss = train_model('Adam', epochs= 10)\n",
        "rmsprop_loss = train_model('RMSprop', epochs= 10)\n",
        "\n",
        "\n",
        "# 5. Plot Training loss\n",
        "plt.plot(sgd_loss, label= 'SGD')\n",
        "plt.plot(adam_loss, label= 'Adam')\n",
        "plt.plot(rmsprop_loss, label= 'RMSprop')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Training Loss')\n",
        "plt.title(\"Optimizer comparision on MNIST\")\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bK9KzepLFUqd",
        "outputId": "1853506d-6be3-4b4f-b121-b7f30841b90d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 132MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 17.3MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 42.2MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 5.30MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGD - Epoch 1, Loss: 1.7424\n",
            "SGD - Epoch 2, Loss: 0.5701\n",
            "SGD - Epoch 3, Loss: 0.3996\n",
            "SGD - Epoch 4, Loss: 0.3454\n",
            "SGD - Epoch 5, Loss: 0.3147\n",
            "SGD - Epoch 6, Loss: 0.2917\n",
            "SGD - Epoch 7, Loss: 0.2728\n",
            "SGD - Epoch 8, Loss: 0.2565\n",
            "SGD - Epoch 9, Loss: 0.2420\n",
            "SGD - Epoch 10, Loss: 0.2286\n",
            "Adam - Epoch 1, Loss: 0.3465\n",
            "Adam - Epoch 2, Loss: 0.1473\n",
            "Adam - Epoch 3, Loss: 0.1000\n",
            "Adam - Epoch 4, Loss: 0.0770\n",
            "Adam - Epoch 5, Loss: 0.0584\n",
            "Adam - Epoch 6, Loss: 0.0469\n",
            "Adam - Epoch 7, Loss: 0.0386\n",
            "Adam - Epoch 8, Loss: 0.0322\n",
            "Adam - Epoch 9, Loss: 0.0254\n",
            "Adam - Epoch 10, Loss: 0.0207\n",
            "RMSprop - Epoch 1, Loss: 0.2919\n",
            "RMSprop - Epoch 2, Loss: 0.1318\n",
            "RMSprop - Epoch 3, Loss: 0.0918\n",
            "RMSprop - Epoch 4, Loss: 0.0689\n",
            "RMSprop - Epoch 5, Loss: 0.0544\n",
            "RMSprop - Epoch 6, Loss: 0.0431\n",
            "RMSprop - Epoch 7, Loss: 0.0345\n",
            "RMSprop - Epoch 8, Loss: 0.0279\n",
            "RMSprop - Epoch 9, Loss: 0.0238\n",
            "RMSprop - Epoch 10, Loss: 0.0196\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparing model's performance\n",
        "\n",
        "```\n",
        "Optimizer     Speed Of Convergence    Final Training Loss    Performance Trend\n",
        "-------------------------------------------------------------------------------------------\n",
        "\n",
        "SGD               Slow                Moderate                Gradual improvement\n",
        "\n",
        "\n",
        "RMSprop           Medium               Good                     Faster than SGD\n",
        "\n",
        "\n",
        "Adam               Fast                Best                   Fast drop in loss, stable\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "0poObwONLCiZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LrIQIVgAruUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.Discuss the considerations and tradeoffs when choosing the appropriate optimizer for a given neural network architecture and task. Consider factors such as convergence speed, stability, and generalization performance."
      ],
      "metadata": {
        "id": "J1AEhn5qrzSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A9. Choosing the right optimizer is a critical decision when training neural networks, as it directly impacts the model's training efficiency, convergence, and ability to generalize to new data. Let‚Äôs explore the key considerations and trade-offs involved in this choice:\n",
        "\n",
        "\n",
        "### 1. ) Convergence Speed\n",
        "\n",
        "**What it Means:** How quickly the optimizer minimizes the loss function and reaches a low error rate.\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "- Adam and RMSprop often converge faster because they adapt learning rates for each parameter.\n",
        "\n",
        "- SGD may converge slower but more steadily, especially with large datasets and properly tuned learning rates.\n",
        "\n",
        "**Tradeoff:**\n",
        "\n",
        "- Faster convergence (e.g., Adam) can sometimes lead to overfitting or convergence to a sharp local minimum.\n",
        "\n",
        "- Slower convergence (SGD) can allow the model to explore more and settle in a flatter minimum, which often generalizes better.\n",
        "\n",
        "\n",
        "### 2. ) Stability During Training\n",
        "\n",
        "**What it Means:** How smoothly the optimizer updates weights without causing loss spikes or divergence.\n",
        "\n",
        "**Considerations:**\n",
        "\n",
        "- Adaptive optimizers (Adam, RMSprop) are more stable‚Äîespecially for noisy gradients, sparse data, or deep networks.\n",
        "\n",
        "- SGD can be unstable without learning rate scheduling or momentum.\n",
        "\n",
        "**Tradeoff:**\n",
        "- High stability (like in Adam) may prevent the model from escaping suboptimal local minima.\n",
        "\n",
        "- Lower stability may mean longer tuning time (learning rate, momentum) but potentially better final performance.\n",
        "\n",
        "\n",
        "### 3. ) Generalization Performance\n",
        "\n",
        "**What it Means:** How well the model performs on unseen data, not just the training set.\n",
        "\n",
        "**Considerations:**\n",
        "- SGD with momentum is known to generalize better in many cases (especially vision tasks).\n",
        "\n",
        "- Adam tends to memorize training data if not regularized properly (risk of overfitting).\n",
        "\n",
        "**Tradeoff:**\n",
        "- Adaptive optimizers may give good training performance but weaker test accuracy.\n",
        "\n",
        "- SGD may require longer training but gives robust generalization.\n",
        "\n",
        "### 4. ) Nature of the Task and Architecture\n",
        "\n",
        "```\n",
        "Task / Model Type\t            Recommended Optimizer            \tReason\n",
        "------------------------------------------------------------------------------------------------\n",
        "\n",
        "-------------------------------------\n",
        "CNNs (e.g., ResNet)\t              SGD + Momentum\t        Better generalization, effective with learning rate decay\n",
        "RNNs / LSTMs\t                  RMSprop / Adam\t          Handles exploding/vanishing gradients well\n",
        "Transformers / NLP\t             Adam / AdamW\t            Works best with sparse gradients and large parameter sets\n",
        "GANs\t                              Adam\t                Helps stabilize unstable training\n",
        "Tabular / Structured Data\t          Adam\t                Good baseline and quick convergence\n",
        "```\n",
        "\n",
        "### 5. ) Computational and Memory Efficiency\n",
        "\n",
        "**Considerations:**\n",
        "- SGD is lightweight and uses minimal memory.\n",
        "\n",
        "- Adam/RMSprop require storing additional parameters (e.g., moment estimates), using more memory and compute.\n",
        "\n",
        "**Tradeoff:**\n",
        "- Adaptive optimizers are easier to tune but more resource-intensive.\n",
        "\n",
        "- SGD is leaner and faster per step, but needs more tuning.\n",
        "\n",
        "\n",
        "### Summary: Key Tradeoffs\n",
        "\n",
        "```\n",
        "Optimizer\t      Speed       \tStability       \tGeneralization\t     Memory Usage        \tUse When‚Ä¶\n",
        "----------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "SGD\t           Slow\t           Low\t                High\t           Low\t Working with image data, need robustness\n",
        "\n",
        "SGD+Momentum\t  Medium\t       Medium\t               High\t           Low\t Vision tasks, deep CNNs\n",
        "\n",
        "RMSprop\t       Fast\t           High\t               Medium        \tMedium\tRNNs, time series, noisy or unstable tasks\n",
        "\n",
        "Adam\t         Very Fast\t    Very High\t             Medium             High\t  NLP, transformers, large models\n",
        "\n",
        "AdamW\t         Fast\t           High\t           Better than Adam\t   High\tFine-tuning pre-trained models\n",
        "\n",
        "```\n"
      ],
      "metadata": {
        "id": "051xxxn_PiKg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Thoughts\n",
        "\n",
        "- Start with Adam for prototyping and early-stage training.\n",
        "\n",
        "- Use SGD with momentum for serious model training (especially in vision tasks).\n",
        "\n",
        "- Always pair your optimizer with:\n",
        "\n",
        "    - Learning rate scheduling\n",
        "\n",
        "    - Regularization techniques (dropout, weight decay)\n",
        "\n",
        "    - Early stopping"
      ],
      "metadata": {
        "id": "4Rf8zBNGXOom"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DJIHEAs9r3V5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4i0Fn8u1r2_5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}