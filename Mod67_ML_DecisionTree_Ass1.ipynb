{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module67 Decision Tree Assignment1"
      ],
      "metadata": {
        "id": "FnxeFA1yKQX3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. Describe the decision tree classifier algorithm and how it works to make predictions."
      ],
      "metadata": {
        "id": "34EHfrZlJ2cj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. A Decision Tree Classifier is a supervised machine learning algorithm used for both classification and regression tasks. It splits the data into subsets based on feature values, forming a tree-like structure where:\n",
        "\n",
        "Internal nodes represent decision points on features.\n",
        "Branches represent outcomes of decisions.\n",
        "Leaf nodes represent class labels.\n",
        "\n",
        "### How It Works:\n",
        "\n",
        "**1.) Split Selection:** At each node, the algorithm selects the feature and threshold that best split the data into subsets, minimizing impurity.\n",
        "\n",
        "**2.) Impurity Metrics:**\n",
        "\n",
        "a.) Gini Index\n",
        "\n",
        "```G = 1 − ∑(from i=1 to C)​ pi^2​ ```\n",
        "\n",
        "b.) Entropy\n",
        "\n",
        "``` H = - ∑(fro i= 1 to C) pi * log 2 (pi ) ```\n",
        "\n",
        "**3.) Recursive Splitting:** Splits continue until stopping criteria are met (e.g., max depth or min samples per leaf).\n",
        "\n",
        "**4.) Prediction:** A new data point traverses the tree based on feature values, and the label of the leaf node is returned."
      ],
      "metadata": {
        "id": "QAmrdS8uJ2fe"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsoeU_FbKWsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification."
      ],
      "metadata": {
        "id": "bbq5XaPBJ2jZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2. The steps are following :-\n",
        "\n",
        "**1.) Start at the Root:**\n",
        "\n",
        "Consider the entire dataset as the root node.\n",
        "\n",
        "**2.) Split the Data:**\n",
        "\n",
        "For each feature, calculate the impurity (Gini or Entropy) before and after splitting:\n",
        "\n",
        "```Information Gain(IG) = H(parent)​ −∑(from k=1 to n)​  (Nk / N) * Hk​ ```\n",
        "\n",
        "H(parent) : Impurity of the parent node.\n",
        "\n",
        "H(k) : Impurity of child k.\n",
        "\n",
        "Nk / N: Weighted proportion of child samples.\n",
        "\n",
        "**3.) Choose the Best Split:**\n",
        "\n",
        "Select the feature and threshold that maximize Information Gain or minimize Gini Index.\n",
        "\n",
        "\n",
        "**4.) Repeat for Subsets:**\n",
        "\n",
        "Recursively apply the process to each child node until a stopping criterion is met.\n",
        "\n",
        "\n",
        "**5.) Assign Labels:**\n",
        "\n",
        "At leaf nodes, assign the majority class or average value."
      ],
      "metadata": {
        "id": "bUty6vGNJ2lN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NblHVvp6KXVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
      ],
      "metadata": {
        "id": "eJw6Xu2vJ2oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. Example Problem: Classify emails as \"Spam\" or \"Not Spam\" based on features like word frequency or sender reputation.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1.) Start with the root node containing all emails.\n",
        "\n",
        "2.) Evaluate splits for each feature (e.g., word_frequency > 50).\n",
        "\n",
        "3.) Select the feature and threshold that best split the data.\n",
        "\n",
        "4.) Recursively split the subsets until stopping criteria are met.\n",
        "\n",
        "5.) Classify emails by traversing the tree to leaf nodes."
      ],
      "metadata": {
        "id": "ZoA1olzHJ2q-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ba5EDbhwKYD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make\n",
        "predictions."
      ],
      "metadata": {
        "id": "hyh8--qJJ2t2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4. Geometric Intuition:\n",
        "\n",
        "1.) Decision trees partition the feature space into axis-aligned regions.\n",
        "\n",
        "2.) Each split divides the space using a vertical or horizontal line, corresponding to a feature threshold.\n",
        "\n",
        "3.) The process continues until all regions (leaf nodes) correspond to a specific class.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "In a 2D feature space with Feature_1 and Feature_2, splits like Feature_1 > 5 and Feature_2 <= 3 create rectangles. Each rectangle is associated with a class label."
      ],
      "metadata": {
        "id": "D26OdEeYJ2wt"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZE_LndYKYoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a\n",
        "classification model."
      ],
      "metadata": {
        "id": "gm0KRdzvJ2zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5. **Definition:**\n",
        "\n",
        "A confusion matrix summarizes the performance of a classification model by comparing predicted vs. actual values.\n",
        "\n",
        "**Structure:**\n",
        "\n",
        "matrix[Actual Positive][Predicted Positive] = TP\n",
        "\n",
        "matrix[Actual Positive][Predicted Negative] = FN\n",
        "\n",
        "matrix[Actual Negative][Predicted Positive] = FP\n",
        "\n",
        "matrix[Actual Negative][Predicted Negative] = TN\n",
        "\n",
        "where,\n",
        "\n",
        "TP = True Positive\n",
        "\n",
        "FN = False Negative\n",
        "\n",
        "FP = False Positive\n",
        "\n",
        "TN = True Negative\n",
        "\n",
        "**Insights:**\n",
        "\n",
        "It helps evaluate metrics like accuracy, precision, recall, and F1-score.\n",
        "\n",
        "**Usage:**\n",
        "\n",
        "Evaluate metrics like accuracy, precision, recall, and F1-score.\n",
        "\n",
        "Analyze error patterns (e.g., high FN or FP).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HQp-wA7yJ22Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Isews3EFKZsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be\n",
        "calculated from it."
      ],
      "metadata": {
        "id": "8XdcXryCJ25O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A6. Example Confusion Matrix:\n",
        "```\n",
        "______________, Predicted Positive, Predicted Negative\n",
        "Actual Positive,\t50,             \t10\n",
        "Actual Negative,\t5,\t              35\n",
        "```\n",
        "\n",
        "Calculations:\n",
        "\n",
        "1.) Precision = TP / (TP + FP) = 50/(50+5) = 0.91\n",
        "\n",
        "2.) Recall = TP / (TP+FN) = 50 / (50+10) = 0.83\n",
        "\n",
        "3.) F1-score = 2 * Precision * Recall / (Precision + Recall) = 2 * 0.91 * 0.83 / (0.91 + 0.83) = 0.87\n",
        "\n"
      ],
      "metadata": {
        "id": "ImdGrvcMJ28s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X5bHCBr2KaPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and\n",
        "explain how this can be done."
      ],
      "metadata": {
        "id": "uPfsbbTpKIN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A7.\n",
        "# Importance:\n",
        "\n",
        "Different problems prioritize different types of errors.\n",
        "\n",
        "Using inappropriate metrics (e.g., accuracy in imbalanced data) can mislead model evaluation.\n",
        "\n",
        "# How to Choose:\n",
        "\n",
        "1.) Domain Knowledge: Understand the cost of errors (FP vs. FN).\n",
        "\n",
        "2.) Imbalanced Data: Use metrics like F1-score, Precision-Recall AUC.\n",
        "\n",
        "3.) Objective: Focus on metrics aligned with business goals.\n"
      ],
      "metadata": {
        "id": "FCZ36zKNKIRI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z6ktSAgvKa_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q8. Provide an example of a classification problem where precision is the most important metric, and\n",
        "explain why."
      ],
      "metadata": {
        "id": "ppT6GpWBKITx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A8. Example: Spam Email Detection.\n",
        "\n",
        "**Reason:** Minimizing false positives (important emails marked as spam) is crucial. High precision ensures fewer important emails are incorrectly flagged."
      ],
      "metadata": {
        "id": "fh8ZuR47KIWY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTv2P-8WKbsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q9. Provide an example of a classification problem where recall is the most important metric, and explain\n",
        "why."
      ],
      "metadata": {
        "id": "9BFvN5ZkKIZB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A9. **Example:** Disease Diagnosis.\n",
        "\n",
        "**Reason:** Minimizing false negatives (undiagnosed patients) is critical. High recall ensures most patients with the disease are correctly identified, even if some false positives occur."
      ],
      "metadata": {
        "id": "w5iMpyE-KIci"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cqT3GVm2Kc0u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
