{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module68 Support Vector Machines Assignment2"
      ],
      "metadata": {
        "id": "97PjTBOTkRJU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
        "algorithms?"
      ],
      "metadata": {
        "id": "LOqKuwKskIgt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A1. The polynomial kernel is a specific type of kernel function used in Support Vector Machines (SVMs) and other algorithms that rely on kernel methods. A polynomial kernel enables the model to represent non-linear relationships by implicitly mapping the data into a higher-dimensional space. The kernel function for a polynomial kernel is given by:\n",
        "\n",
        "``` k(x,x') = (纬 . xT x' + r)^d ```\n",
        "\n",
        "Where:\n",
        "\n",
        "x and x' are input vectors.\n",
        "\n",
        "纬 is a scaling factor.\n",
        "\n",
        "r is a constant that shifts the hyperplane.\n",
        "\n",
        "d is the degree of the polynomial.\n",
        "\n",
        "The polynomial kernel allows algorithms to learn boundaries that are curved or more complex than linear ones. This is useful for datasets where the relationship between input features and the target variable is non-linear.\n"
      ],
      "metadata": {
        "id": "XkDzfSnhkIdG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o4Tm0aoqkJKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?"
      ],
      "metadata": {
        "id": "_FPm_A25kIaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A2. To implement an SVM with a polynomial kernel in Python using Scikit-learn:"
      ],
      "metadata": {
        "id": "-DQDzZMykIX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, n_clusters_per_class= 2, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create and train the SVM with a polynomial kernel\n",
        "svc_poly = SVC(kernel='poly', degree=3, C=1.0)\n",
        "svc_poly.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = svc_poly.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy with Polynomial Kernel:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4JltbWkkJ5h",
        "outputId": "9f236473-4d7a-4e10-a118-57ccf6bc4c52"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with Polynomial Kernel: 0.8466666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOTUGVvUmVR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?"
      ],
      "metadata": {
        "id": "KJRJ4Hv0kIVX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A3. The 系-insensitive tube specifies a margin of tolerance around the predicted values, within which errors are ignored.\n",
        "\n",
        "**Increasing 系:**\n",
        "\n",
        "Makes the margin wider.\n",
        "\n",
        "Reduces the number of support vectors since fewer data points fall outside the margin.\n",
        "\n",
        "This simplifies the model but can lead to underfitting."
      ],
      "metadata": {
        "id": "bMLbmggckISk"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rpBZWM3_kKl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
        "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
        "and provide examples of when you might want to increase or decrease its value?"
      ],
      "metadata": {
        "id": "A5XWv3qHkIPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A4.\n",
        "\n",
        "1.) **Kernel Function:**\n",
        "\n",
        "Determines how the input space is mapped to the feature space.\n",
        "\n",
        "Example:\n",
        "\n",
        "Use a linear kernel for linearly separable data.\n",
        "\n",
        "Use an RBF kernel for complex, non-linear relationships.\n",
        "\n",
        "\n",
        "2.) **C Parameter:**\n",
        "\n",
        "Controls the trade-off between a smooth decision boundary and classifying training points correctly.\n",
        "\n",
        "**Increase C:** Reduces margin width but fits the data more tightly (risk of overfitting).\n",
        "\n",
        "**Decrease C:** Increases margin width but allows for more tolerance to misclassification (risk of underfitting).\n",
        "\n",
        "3.) **Epsilon ():**\n",
        "\n",
        "Specifies the margin of tolerance for error in predictions.\n",
        "\n",
        "**Increase 系:** Fewer support vectors, simpler model (risk of underfitting).\n",
        "\n",
        "**Decrease 系:** More support vectors, more precise fit (risk of overfitting).\n",
        "\n",
        "4.) **Gamma:**\n",
        "\n",
        "Defines the influence of a single training example.\n",
        "\n",
        "**High Gamma:** Focuses on close neighbors (complex model, risk of overfitting).\n",
        "\n",
        "**Low Gamma:** Considers distant points (simpler model, risk of underfitting).\n"
      ],
      "metadata": {
        "id": "vCe2QMCPkIND"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NSomQ91bkLW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q5. Assignment:\n",
        "\n",
        "1. Import the necessary libraries and load the dataset.\n",
        "\n",
        "2. Split the dataset into training and testing sets.\n",
        "\n",
        "3. Preprocess the data using any technique of your choice (e.g. scaling, normalization).\n",
        "\n",
        "4. Create an instance of the SVC classifier and train it on the training data.\n",
        "\n",
        "5. Use the trained classifier to predict the labels of the testing data.\n",
        "\n",
        "6. Evaluate the performance of the classifier using any metric of your choice (e.g. accuracy,\n",
        "precision, recall, F1-score).\n",
        "\n",
        "7. Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomizedSearchCV to\n",
        "improve its performance\n",
        "\n",
        " Train the tuned classifier on the entire dataset\n",
        "\n",
        " Save the trained classifier to a file for future use.\n",
        "\n",
        "Note: You can use any dataset of your choice for this assignment, but make sure it is suitable for\n",
        "classification and has a sufficient number of features and samples."
      ],
      "metadata": {
        "id": "RCP90i-akIKM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A5. Key Steps Explained:\n",
        "\n",
        "1.) **Dataset:** Used the Wine dataset, suitable for multi-class classification.\n",
        "\n",
        "2.) **Preprocessing:** Standardized features to improve model performance.\n",
        "\n",
        "3.) **Model Training:** Used a linear SVM classifier.\n",
        "\n",
        "4.) **Evaluation:** Used classification metrics (e.g., accuracy, precision, recall).\n",
        "\n",
        "5.) **Hyperparameter Tuning:** Optimized parameters using GridSearchCV.\n",
        "\n",
        "6.) **Save Model:** Saved the trained model to a file for reuse."
      ],
      "metadata": {
        "id": "d3PUM187kIHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "\n",
        "# Load dataset\n",
        "data = load_wine()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "# Preprocess data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create and train an SVM classifier\n",
        "svc = SVC(kernel='linear', random_state=42)\n",
        "svc.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = svc.predict(X_test)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Hyperparameter tuning with GridSearchCV\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf'],\n",
        "    'degree': [2, 3, 4],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "grid_search = GridSearchCV(SVC(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best parameters\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "# Train the best model on the entire dataset\n",
        "best_model = grid_search.best_estimator_\n",
        "best_model.fit(X_train, y_train)\n",
        "\n",
        "# Save the model for future use\n",
        "joblib.dump(best_model, \"svm_classifier.pkl\")\n",
        "\n",
        "# Load the saved model (optional)\n",
        "loaded_model = joblib.load(\"svm_classifier.pkl\")\n",
        "print(\"Loaded Model Accuracy:\", loaded_model.score(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxkk_x0CkMHd",
        "outputId": "552cfed0-2e2b-44f4-b890-bb9055ffd31a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97        18\n",
            "           1       0.95      0.95      0.95        21\n",
            "           2       1.00      0.93      0.97        15\n",
            "\n",
            "    accuracy                           0.96        54\n",
            "   macro avg       0.97      0.96      0.96        54\n",
            "weighted avg       0.96      0.96      0.96        54\n",
            "\n",
            "Best Parameters: {'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "Loaded Model Accuracy: 0.9814814814814815\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3aCkz3gepMqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}